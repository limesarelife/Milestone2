{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "908e1448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "462c1d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftry2 = pd.read_csv(\"posts_st.txt\",\n",
    "                    sep = '|',\n",
    "                    names = ['AUTHOR','ID','SCORE','CREATED_DATE','TITLE','NUM_COMMENTS','SELFTEXT'],\n",
    "                    header=None, lineterminator = \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fd963eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>ID</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>CREATED_DATE</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>NUM_COMMENTS</th>\n",
       "      <th>SELFTEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43411</th>\n",
       "      <td>Floker1</td>\n",
       "      <td>cdwiln</td>\n",
       "      <td>24310.0</td>\n",
       "      <td>2019-07-16</td>\n",
       "      <td>Imagine Mike and Nancy finding out that all th...</td>\n",
       "      <td>718</td>\n",
       "      <td>\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43155</th>\n",
       "      <td>Utgoffalec</td>\n",
       "      <td>cees1t</td>\n",
       "      <td>21899.0</td>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>Hi! My name is Alec Utgoff and I play Dr. Alex...</td>\n",
       "      <td>1659</td>\n",
       "      <td>You can follow me on Twitter @AlecUtgoff and I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42043</th>\n",
       "      <td>coloredneon</td>\n",
       "      <td>cibkdz</td>\n",
       "      <td>16975.0</td>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>Wills storyline doesnt seem to be about sexual...</td>\n",
       "      <td>813</td>\n",
       "      <td>I keep seeing posts and comments about Wills s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43291</th>\n",
       "      <td>brettcliffordgelman</td>\n",
       "      <td>ce4jk4</td>\n",
       "      <td>13026.0</td>\n",
       "      <td>2019-07-16</td>\n",
       "      <td>Im Brett Gelman aka Murray from Stranger Thing...</td>\n",
       "      <td>1225</td>\n",
       "      <td>Hi Reddit! Brett Gelman here. Im an actor and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45112</th>\n",
       "      <td>AndreyIvchenko</td>\n",
       "      <td>cbiolx</td>\n",
       "      <td>10260.0</td>\n",
       "      <td>2019-07-10</td>\n",
       "      <td>Hello Reddit family, it's Andrey Ivchenko here...</td>\n",
       "      <td>1114</td>\n",
       "      <td>Really excited to be here with you all today f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62162</th>\n",
       "      <td>The only other bit of evidence I have is that ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62163</th>\n",
       "      <td>\\r</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62164</th>\n",
       "      <td>Excuse me I'm on mobile\\r</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65038</th>\n",
       "      <td>\\r</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65039</th>\n",
       "      <td>I NEED ANSWERS GODDAMIT WHERE IS SEASON 2 HOW ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65645 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  AUTHOR      ID    SCORE  \\\n",
       "43411                                            Floker1  cdwiln  24310.0   \n",
       "43155                                         Utgoffalec  cees1t  21899.0   \n",
       "42043                                        coloredneon  cibkdz  16975.0   \n",
       "43291                                brettcliffordgelman  ce4jk4  13026.0   \n",
       "45112                                     AndreyIvchenko  cbiolx  10260.0   \n",
       "...                                                  ...     ...      ...   \n",
       "62162  The only other bit of evidence I have is that ...     NaN      NaN   \n",
       "62163                                                 \\r     NaN      NaN   \n",
       "62164                          Excuse me I'm on mobile\\r     NaN      NaN   \n",
       "65038                                                 \\r     NaN      NaN   \n",
       "65039  I NEED ANSWERS GODDAMIT WHERE IS SEASON 2 HOW ...     NaN      NaN   \n",
       "\n",
       "      CREATED_DATE                                              TITLE  \\\n",
       "43411   2019-07-16  Imagine Mike and Nancy finding out that all th...   \n",
       "43155   2019-07-17  Hi! My name is Alec Utgoff and I play Dr. Alex...   \n",
       "42043   2019-07-27  Wills storyline doesnt seem to be about sexual...   \n",
       "43291   2019-07-16  Im Brett Gelman aka Murray from Stranger Thing...   \n",
       "45112   2019-07-10  Hello Reddit family, it's Andrey Ivchenko here...   \n",
       "...            ...                                                ...   \n",
       "62162          NaN                                                NaN   \n",
       "62163          NaN                                                NaN   \n",
       "62164          NaN                                                NaN   \n",
       "65038          NaN                                                NaN   \n",
       "65039          NaN                                                NaN   \n",
       "\n",
       "      NUM_COMMENTS                                           SELFTEXT  \n",
       "43411          718                                                 \\r  \n",
       "43155         1659  You can follow me on Twitter @AlecUtgoff and I...  \n",
       "42043          813  I keep seeing posts and comments about Wills s...  \n",
       "43291         1225  Hi Reddit! Brett Gelman here. Im an actor and ...  \n",
       "45112         1114  Really excited to be here with you all today f...  \n",
       "...            ...                                                ...  \n",
       "62162          NaN                                                NaN  \n",
       "62163          NaN                                                NaN  \n",
       "62164          NaN                                                NaN  \n",
       "65038          NaN                                                NaN  \n",
       "65039          NaN                                                NaN  \n",
       "\n",
       "[65645 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftry2.sort_values(by=['SCORE'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d5e8867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65645 entries, 0 to 65644\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   AUTHOR        65645 non-null  object \n",
      " 1   ID            65507 non-null  object \n",
      " 2   SCORE         65507 non-null  float64\n",
      " 3   CREATED_DATE  65507 non-null  object \n",
      " 4   TITLE         65473 non-null  object \n",
      " 5   NUM_COMMENTS  65494 non-null  object \n",
      " 6   SELFTEXT      65500 non-null  object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "dftry2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3e27ef",
   "metadata": {},
   "source": [
    "### Removing where the title or the selftext are null and removing the posts where the moderator for the Subreddit deleted/removed the post or the original author deleted/removed the post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "981939d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftry2.dropna(subset=['TITLE'], inplace = True)\n",
    "dftry2.dropna(subset=['SELFTEXT'], inplace = True)\n",
    "df_touse = dftry2[dftry2['SELFTEXT'] != \"[removed]\"].copy()\n",
    "df_to_use_fin = df_touse[df_touse['SELFTEXT'] != \"[deleted]\"].copy()\n",
    "df_to_use_fin['FULL_POSTS'] = df_to_use_fin['TITLE']+\".\"+\" \"+df_touse['SELFTEXT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0a29ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65468, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_use_fin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67075b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = df_to_use_fin[df_to_use_fin['ID'] == 'vow5wm']\n",
    "#check = dftry[dftry['ID'] == '7pzv67']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cb90f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>ID</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>CREATED_DATE</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>NUM_COMMENTS</th>\n",
       "      <th>SELFTEXT</th>\n",
       "      <th>FULL_POSTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15185</th>\n",
       "      <td>StrangerTesting</td>\n",
       "      <td>vow5wm</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>Stranger Things Season 4 Volume 2 Series Discu...</td>\n",
       "      <td>1</td>\n",
       "      <td># In this thread you can discuss the entirety ...</td>\n",
       "      <td>Stranger Things Season 4 Volume 2 Series Discu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AUTHOR      ID  SCORE CREATED_DATE  \\\n",
       "15185  StrangerTesting  vow5wm    1.0   2022-07-01   \n",
       "\n",
       "                                                   TITLE NUM_COMMENTS  \\\n",
       "15185  Stranger Things Season 4 Volume 2 Series Discu...            1   \n",
       "\n",
       "                                                SELFTEXT  \\\n",
       "15185  # In this thread you can discuss the entirety ...   \n",
       "\n",
       "                                              FULL_POSTS  \n",
       "15185  Stranger Things Season 4 Volume 2 Series Discu...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47220668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65468"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_to_use_fin.ID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7215aece",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_use_fin['CREATED_DATE'] = pd.to_datetime(df_to_use_fin['CREATED_DATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c056df61",
   "metadata": {},
   "source": [
    "### Only keeping posts from the release date of season 3 to current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "450d6137",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_use_fin = df_to_use_fin[df_to_use_fin['CREATED_DATE']> \"2019-07-04\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5327fcb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48310, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_use_fin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3377738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>ID</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>CREATED_DATE</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>NUM_COMMENTS</th>\n",
       "      <th>SELFTEXT</th>\n",
       "      <th>FULL_POSTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emergency-Okra-6432</td>\n",
       "      <td>y23awh</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-10-12</td>\n",
       "      <td>Number Eighth's removal from the show?!</td>\n",
       "      <td>1</td>\n",
       "      <td>[removed]\\r</td>\n",
       "      <td>Number Eighth's removal from the show?!. [remo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lower-Adhesiveness-3</td>\n",
       "      <td>y1yfqt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-10-12</td>\n",
       "      <td>The upsidedown turns on Vecna, can he survive?</td>\n",
       "      <td>1</td>\n",
       "      <td>For some reason Vecna loses all his control ov...</td>\n",
       "      <td>The upsidedown turns on Vecna, can he survive?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mrs_bombastic22</td>\n",
       "      <td>y1yf6g</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-10-12</td>\n",
       "      <td>Season 4 rewatch - 2 questions</td>\n",
       "      <td>1</td>\n",
       "      <td>When 001 went on his killing spree in the lab....</td>\n",
       "      <td>Season 4 rewatch - 2 questions. When 001 went ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YakivHerasymenko</td>\n",
       "      <td>y1x8y6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-10-12</td>\n",
       "      <td>What will the Stranger Things group(suppose ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>[removed]\\r</td>\n",
       "      <td>What will the Stranger Things group(suppose ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>andrew_cocos</td>\n",
       "      <td>y1vpaj</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-10-12</td>\n",
       "      <td>Would someone explain me the whole \"favorite s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[removed]\\r</td>\n",
       "      <td>Would someone explain me the whole \"favorite s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48348</th>\n",
       "      <td>Ikasaurus</td>\n",
       "      <td>c99gn8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>Spoiler conspiracy theory about ending.</td>\n",
       "      <td>7</td>\n",
       "      <td>[removed]\\r</td>\n",
       "      <td>Spoiler conspiracy theory about ending.. [remo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48349</th>\n",
       "      <td>Aseph88</td>\n",
       "      <td>c99g2p</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>[minor spoilers]Thought Kline's sign looked fa...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sorry for getting political but couldnt help b...</td>\n",
       "      <td>[minor spoilers]Thought Kline's sign looked fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48350</th>\n",
       "      <td>Imperial3agle</td>\n",
       "      <td>c99fxn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>[No Spoilers] How sure are we that there will ...</td>\n",
       "      <td>10</td>\n",
       "      <td>By the way, I have only seen the first 4 episo...</td>\n",
       "      <td>[No Spoilers] How sure are we that there will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48351</th>\n",
       "      <td>dudeRedditSucksNow</td>\n",
       "      <td>c99ft9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>In episode 2 where Joyce is watching Friends, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>We can confirm an exact timeline of the show u...</td>\n",
       "      <td>In episode 2 where Joyce is watching Friends, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48352</th>\n",
       "      <td>Marty_McFlyJR</td>\n",
       "      <td>c99fc6</td>\n",
       "      <td>627.0</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>Uhm... Why so I feel like I'm the only one...</td>\n",
       "      <td>69</td>\n",
       "      <td>That feels bad about Billy? He was literally a...</td>\n",
       "      <td>Uhm... Why so I feel like I'm the only one.......</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48310 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AUTHOR      ID  SCORE CREATED_DATE  \\\n",
       "0       Emergency-Okra-6432  y23awh    1.0   2022-10-12   \n",
       "1      Lower-Adhesiveness-3  y1yfqt    1.0   2022-10-12   \n",
       "2           mrs_bombastic22  y1yf6g    1.0   2022-10-12   \n",
       "3          YakivHerasymenko  y1x8y6    1.0   2022-10-12   \n",
       "4              andrew_cocos  y1vpaj    1.0   2022-10-12   \n",
       "...                     ...     ...    ...          ...   \n",
       "48348             Ikasaurus  c99gn8    3.0   2019-07-05   \n",
       "48349               Aseph88  c99g2p    1.0   2019-07-05   \n",
       "48350         Imperial3agle  c99fxn    1.0   2019-07-05   \n",
       "48351    dudeRedditSucksNow  c99ft9    1.0   2019-07-05   \n",
       "48352         Marty_McFlyJR  c99fc6  627.0   2019-07-05   \n",
       "\n",
       "                                                   TITLE NUM_COMMENTS  \\\n",
       "0                Number Eighth's removal from the show?!            1   \n",
       "1         The upsidedown turns on Vecna, can he survive?            1   \n",
       "2                         Season 4 rewatch - 2 questions            1   \n",
       "3      What will the Stranger Things group(suppose ev...            0   \n",
       "4      Would someone explain me the whole \"favorite s...            1   \n",
       "...                                                  ...          ...   \n",
       "48348            Spoiler conspiracy theory about ending.            7   \n",
       "48349  [minor spoilers]Thought Kline's sign looked fa...            0   \n",
       "48350  [No Spoilers] How sure are we that there will ...           10   \n",
       "48351  In episode 2 where Joyce is watching Friends, ...            2   \n",
       "48352      Uhm... Why so I feel like I'm the only one...           69   \n",
       "\n",
       "                                                SELFTEXT  \\\n",
       "0                                            [removed]\\r   \n",
       "1      For some reason Vecna loses all his control ov...   \n",
       "2      When 001 went on his killing spree in the lab....   \n",
       "3                                            [removed]\\r   \n",
       "4                                            [removed]\\r   \n",
       "...                                                  ...   \n",
       "48348                                        [removed]\\r   \n",
       "48349  Sorry for getting political but couldnt help b...   \n",
       "48350  By the way, I have only seen the first 4 episo...   \n",
       "48351  We can confirm an exact timeline of the show u...   \n",
       "48352  That feels bad about Billy? He was literally a...   \n",
       "\n",
       "                                              FULL_POSTS  \n",
       "0      Number Eighth's removal from the show?!. [remo...  \n",
       "1      The upsidedown turns on Vecna, can he survive?...  \n",
       "2      Season 4 rewatch - 2 questions. When 001 went ...  \n",
       "3      What will the Stranger Things group(suppose ev...  \n",
       "4      Would someone explain me the whole \"favorite s...  \n",
       "...                                                  ...  \n",
       "48348  Spoiler conspiracy theory about ending.. [remo...  \n",
       "48349  [minor spoilers]Thought Kline's sign looked fa...  \n",
       "48350  [No Spoilers] How sure are we that there will ...  \n",
       "48351  In episode 2 where Joyce is watching Friends, ...  \n",
       "48352  Uhm... Why so I feel like I'm the only one.......  \n",
       "\n",
       "[48310 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_use_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c93748a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ed0567c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04e7f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import nltk\n",
    "import en_core_web_sm\n",
    "#nlp = en_core_web_sm.load()\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcd7d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Cleaning Function\n",
    "import re\n",
    "\n",
    "def clean(text):\n",
    "    allowed_postags=[\"NOUN\", \"VERB\", \"ADJ\", \"ADV\", \"ADP\", \"PROPN\"]\n",
    "    \n",
    "    try: \n",
    "        text1 = re.sub(r\"http\\S+\", \"\", text)\n",
    "        #Convert text in lower case\n",
    "        text2 = text1.lower()\n",
    "        #text3 = text2.replace(\"[^a-zA-Z#]\", \" \")\n",
    "        #Removing Punctuations\n",
    "        punc_removed = text2.translate(str.maketrans('', '', string.punctuation))\n",
    "        doc= nlp(punc_removed)\n",
    "        text_out = [token.lemma_ for token in doc if token.is_stop == False and \\\n",
    "                    token.is_alpha and len(token)>2 and token.pos_ in allowed_postags\\\n",
    "                   ]\n",
    "        #txt = ' '.join(text_out)\n",
    "    except:\n",
    "        #txt = ''\n",
    "        text_out = ''\n",
    "    return text_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1825580",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_use_fin['token_lemma'] = df_to_use_fin['FULL_POSTS'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f439c06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Tamara\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarity checked successfull\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def polarity(text):\n",
    "    pol = sid.polarity_scores(text)\n",
    "    return pol\n",
    "#polarity checking\n",
    "def joiner(text):\n",
    "    txt = ' '.join(text)\n",
    "    return txt\n",
    "df_to_use_fin['FULL_POSTS_CLEAN'] = df_to_use_fin['token_lemma'].apply(joiner)\n",
    "df_to_use_fin['polarity'] = df_to_use_fin['FULL_POSTS_CLEAN'].apply(polarity)\n",
    "df_to_use_fin['compound']  = df_to_use_fin['polarity'].apply(lambda score_dict: score_dict['compound'])\n",
    "\n",
    "df_to_use_fin['sentiment'] = df_to_use_fin['compound'].apply(lambda x: \"Positive\" if x>0 else(\"Negative\" if x<0 else \"Neutral\") )\n",
    "print(\"polarity checked successfull\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bcb6b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48310, 13)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_use_fin.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b943840c",
   "metadata": {},
   "source": [
    "### Remove posts where the tokenized and lemmatized title+selftext, aka POSTS, have a length less than 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a40ceed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39215, 14)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_use_fin['tok_len'] = df_to_use_fin['token_lemma'].apply(lambda x: len(x))\n",
    "df_to_use_fin.groupby(['tok_len'])['tok_len'].count()#[48310]\n",
    "df_to_use_fin = df_to_use_fin[df_to_use_fin['tok_len']>=5].copy()\n",
    "df_to_use_fin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21b3670b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>ID</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>CREATED_DATE</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>NUM_COMMENTS</th>\n",
       "      <th>SELFTEXT</th>\n",
       "      <th>FULL_POSTS</th>\n",
       "      <th>token_lemma</th>\n",
       "      <th>FULL_POSTS_CLEAN</th>\n",
       "      <th>polarity</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tok_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lower-Adhesiveness-3</td>\n",
       "      <td>y1yfqt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-10-12</td>\n",
       "      <td>The upsidedown turns on Vecna, can he survive?</td>\n",
       "      <td>1</td>\n",
       "      <td>For some reason Vecna loses all his control ov...</td>\n",
       "      <td>The upsidedown turns on Vecna, can he survive?...</td>\n",
       "      <td>[upsidedown, turn, vecna, survive, reason, vec...</td>\n",
       "      <td>upsidedown turn vecna survive reason vecna los...</td>\n",
       "      <td>{'neg': 0.365, 'neu': 0.635, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.8720</td>\n",
       "      <td>Negative</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mrs_bombastic22</td>\n",
       "      <td>y1yf6g</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-10-12</td>\n",
       "      <td>Season 4 rewatch - 2 questions</td>\n",
       "      <td>1</td>\n",
       "      <td>When 001 went on his killing spree in the lab....</td>\n",
       "      <td>Season 4 rewatch - 2 questions. When 001 went ...</td>\n",
       "      <td>[season, rewatch, question, go, killing, spree...</td>\n",
       "      <td>season rewatch question go killing spree lab k...</td>\n",
       "      <td>{'neg': 0.503, 'neu': 0.497, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.8779</td>\n",
       "      <td>Negative</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AUTHOR      ID  SCORE CREATED_DATE  \\\n",
       "1  Lower-Adhesiveness-3  y1yfqt    1.0   2022-10-12   \n",
       "2       mrs_bombastic22  y1yf6g    1.0   2022-10-12   \n",
       "\n",
       "                                            TITLE NUM_COMMENTS  \\\n",
       "1  The upsidedown turns on Vecna, can he survive?            1   \n",
       "2                  Season 4 rewatch - 2 questions            1   \n",
       "\n",
       "                                            SELFTEXT  \\\n",
       "1  For some reason Vecna loses all his control ov...   \n",
       "2  When 001 went on his killing spree in the lab....   \n",
       "\n",
       "                                          FULL_POSTS  \\\n",
       "1  The upsidedown turns on Vecna, can he survive?...   \n",
       "2  Season 4 rewatch - 2 questions. When 001 went ...   \n",
       "\n",
       "                                         token_lemma  \\\n",
       "1  [upsidedown, turn, vecna, survive, reason, vec...   \n",
       "2  [season, rewatch, question, go, killing, spree...   \n",
       "\n",
       "                                    FULL_POSTS_CLEAN  \\\n",
       "1  upsidedown turn vecna survive reason vecna los...   \n",
       "2  season rewatch question go killing spree lab k...   \n",
       "\n",
       "                                            polarity  compound sentiment  \\\n",
       "1  {'neg': 0.365, 'neu': 0.635, 'pos': 0.0, 'comp...   -0.8720  Negative   \n",
       "2  {'neg': 0.503, 'neu': 0.497, 'pos': 0.0, 'comp...   -0.8779  Negative   \n",
       "\n",
       "   tok_len  \n",
       "1       23  \n",
       "2       11  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_use_fin.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e291885f",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08816373",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = []\n",
    "for i in range(len(df_to_use_fin)):\n",
    "    val.append(df_to_use_fin['token_lemma'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e956da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models,corpora\n",
    "dictionary = corpora.Dictionary(val)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd046c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5dc889",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in val]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9098c77a",
   "metadata": {},
   "source": [
    "### LDA first go - no tuning and 10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d0c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "lda_model =  gensim.models.LdaModel(bow_corpus, num_topics = 10, \n",
    "                                        passes = 8,alpha = 'auto',\n",
    "                                        random_state = 100,chunksize = 1000,\n",
    "                                        )\n",
    "#lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60094a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing Topics and Its keywords\n",
    "num_topics = 10\n",
    "for i in range(num_topics):\n",
    "    tt = lda_model.get_topic_terms(i,10)\n",
    "    topic = ', '.join([dictionary[pair[0]] for pair in tt])\n",
    "    print(\"TOPIC: {} \\nTOPIC WORDS : {}\".format(i+1, topic ))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d9ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, \n",
    "                                     texts=df_to_use_fin['token_lemma'], \n",
    "                                     dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd747d62",
   "metadata": {},
   "source": [
    "### Finding ideal number of topics for LDA & Hyper parameter Tuning using ideal number of topics for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd62415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supporting function\n",
    "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=bow_corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=1000,\n",
    "                                           passes=8,\n",
    "                                           alpha=a,\n",
    "                                           eta=b)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, \n",
    "                                         texts=df_to_use_fin['token_lemma'], \n",
    "                                         dictionary=dictionary, \n",
    "                                         coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2705828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tqdm\n",
    "#grid = {}\n",
    "#grid['Validation_Set'] = {}\n",
    "#Topics range\n",
    "min_topics = 4\n",
    "max_topics = 12\n",
    "step_size = 2\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "#Alpha parameter\n",
    "alpha = list('symmetric','asymmetric','auto')\n",
    "#Beta parameter\n",
    "beta = list('symmetric','asymmetric','auto')\n",
    "#Validation set len\n",
    "num_of_docs = len(bow_corpus)\n",
    "#corpus_sets = [gensim.utils.ClippedCorpus(bow_corpus, round(num_of_docs*0.75,0)),bow_corpus]\n",
    "corpus_title = '100% Corpus'\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "\n",
    "#iterate through validation corpuses\n",
    "#for i in range(len(num_of_docs)):\n",
    "#iterate through number of topics\n",
    "for k in topics_range:\n",
    "    #iterate through alpha values\n",
    "    for a in alpha:\n",
    "        #iterare through beta values\n",
    "        for b in beta:\n",
    "            #get the coherence score for the given parameters\n",
    "            cv = compute_coherence_values(corpus=bow_corpus, \n",
    "                                          dictionary=dictionary, \n",
    "                                          k=k, a=a, b=b)\n",
    "            #Save the model results\n",
    "            model_results['Validation_Set'].append(corpus_title)\n",
    "            model_results['Topics'].append(k)\n",
    "            model_results['Alpha'].append(a)\n",
    "            model_results['Beta'].append(b)\n",
    "            model_results['Coherence'].append(cv)\n",
    "                    \n",
    "\n",
    "pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
    "#pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072f06fd",
   "metadata": {},
   "source": [
    "### Running Final LDA model with ideal tuned parameters and ideal topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f3976",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_optimals = pd.read_csv(\"lda_tuning_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c086345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_final = gensim.models.LdaMulticore(corpus=bow_corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=#8, \n",
    "                                           random_state=#100,\n",
    "                                           chunksize=#100,\n",
    "                                           passes=#10,\n",
    "                                           alpha=#0.01,\n",
    "                                           eta=#0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dd0c1a",
   "metadata": {},
   "source": [
    "### look at perplexity score and log likelihood and distance measures/similarity measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2027fd",
   "metadata": {},
   "source": [
    "### Try tuned model with our dicitonary based on our corpus of docs versus the standard genism dictionary.  This is because our dictionary has around 56,308 keys; this is very long. So we are going to try both ways and check scores again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4146ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d47e6107",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c30f881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import the dataset from sklearn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# import other required libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# string manipulation libs\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# viz libs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0561028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>ID</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>CREATED_DATE</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>NUM_COMMENTS</th>\n",
       "      <th>SELFTEXT</th>\n",
       "      <th>FULL_POSTS</th>\n",
       "      <th>token_lemma</th>\n",
       "      <th>FULL_POSTS_CLEAN</th>\n",
       "      <th>polarity</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tok_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lower-Adhesiveness-3</td>\n",
       "      <td>y1yfqt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-10-12</td>\n",
       "      <td>The upsidedown turns on Vecna, can he survive?</td>\n",
       "      <td>1</td>\n",
       "      <td>For some reason Vecna loses all his control ov...</td>\n",
       "      <td>The upsidedown turns on Vecna, can he survive?...</td>\n",
       "      <td>[upsidedown, turn, vecna, survive, reason, vec...</td>\n",
       "      <td>upsidedown turn vecna survive reason vecna los...</td>\n",
       "      <td>{'neg': 0.365, 'neu': 0.635, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.872</td>\n",
       "      <td>Negative</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AUTHOR      ID  SCORE CREATED_DATE  \\\n",
       "1  Lower-Adhesiveness-3  y1yfqt    1.0   2022-10-12   \n",
       "\n",
       "                                            TITLE NUM_COMMENTS  \\\n",
       "1  The upsidedown turns on Vecna, can he survive?            1   \n",
       "\n",
       "                                            SELFTEXT  \\\n",
       "1  For some reason Vecna loses all his control ov...   \n",
       "\n",
       "                                          FULL_POSTS  \\\n",
       "1  The upsidedown turns on Vecna, can he survive?...   \n",
       "\n",
       "                                         token_lemma  \\\n",
       "1  [upsidedown, turn, vecna, survive, reason, vec...   \n",
       "\n",
       "                                    FULL_POSTS_CLEAN  \\\n",
       "1  upsidedown turn vecna survive reason vecna los...   \n",
       "\n",
       "                                            polarity  compound sentiment  \\\n",
       "1  {'neg': 0.365, 'neu': 0.635, 'pos': 0.0, 'comp...    -0.872  Negative   \n",
       "\n",
       "   tok_len  \n",
       "1       23  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_to_use_fin.copy()\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46ddff69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tamara\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "tf_idf_vectorizor = TfidfVectorizer(max_features = 20000) #1\n",
    "tf_idf = tf_idf_vectorizor.fit_transform(list(df_to_use_fin['FULL_POSTS_CLEAN'])) #2\n",
    "#tf_idf_array = tf_idf.toarray() \n",
    "X = pd.DataFrame(tf_idf.toarray(),columns=tf_idf_vectorizor.get_feature_names())#4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5fafe87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39215, 20000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "616f3bbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, -1}\n"
     ]
    }
   ],
   "source": [
    "db = DBSCAN(eps=0.1, min_samples=2).fit(X)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "print(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b68ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters_ = len(set(labels))\n",
    "n_noise_ = list(labels).count(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b6b4679",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "range_min = [x for x in range(2, 51, 1)]\n",
    "range_eps = [x / 100.0 for x in range(1, 51, 1)] +  [y / 10.0 for y in range(1, 51, 1)] +  [round(z, 2) for z in np.arange(1.10, 1.31, 0.01)]                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a917d120",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for m in range_min:\n",
    "\n",
    "    for e in range_eps:\n",
    "\n",
    "        model_1 = DBSCAN(eps = e, min_samples = m).fit(X)\n",
    "\n",
    "        core_samples_mask = np.zeros_like(model_1.labels_, dtype = bool)\n",
    "\n",
    "        core_samples_mask[model_1.core_sample_indices_] = True\n",
    "\n",
    "        labels = model_1.labels_\n",
    "\n",
    "        if len( set(labels) ) > 1:\n",
    "\n",
    "            silhouette_Avg = silhouette_score(X, labels)\n",
    "\n",
    "            if silhouette_Avg > 0:\n",
    "\n",
    "                dic[str(m) + \" - \" + str(e)] = silhouette_Avg\n",
    "\n",
    "                print(\"min-sample value is: \" + str(m) + \" eps value is: \" + str(e) , \"The avearge silhouette_score is :\",                               silhouette_Avg)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa9d433",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_key = max(dic, key = dic.get)\n",
    "print(\"parameter values are: \", max_key)\n",
    "print(\"maximum silhouette score value is: \", dic[max_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3753e8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "model = DBSCAN(eps = 1.22, min_samples = 13).fit(X)\n",
    "core_samples_mask = np.zeros_like(model.labels_, dtype = bool)\n",
    "\n",
    "core_samples_mask[model.core_sample_indices_] = True\n",
    "\n",
    "labels = model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8594335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "n_outlier = list(labels).count(-1)\n",
    "\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "print('Estimated number of noise points: %d' % n_outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8807b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "print(\"Estimated number of clusters: %d\" % n_clusters)\n",
    "print(\"\\n\")\n",
    "print(\"Estimated number of outlier points: %d\" % n_outlier)\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
