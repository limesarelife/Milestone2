{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "908e1448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "462c1d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftry2 = pd.read_csv(\"posts_st.txt\",\n",
    "                    sep = '|',\n",
    "                    names = ['AUTHOR','ID','SCORE','CREATED_DATE','TITLE','NUM_COMMENTS','SELFTEXT'],\n",
    "                    header=None, lineterminator = \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fd963eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>ID</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>CREATED_DATE</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>NUM_COMMENTS</th>\n",
       "      <th>SELFTEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43395</th>\n",
       "      <td>Floker1</td>\n",
       "      <td>cdwiln</td>\n",
       "      <td>24310</td>\n",
       "      <td>2019-07-16</td>\n",
       "      <td>Imagine Mike and Nancy finding out that all th...</td>\n",
       "      <td>718</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43139</th>\n",
       "      <td>Utgoffalec</td>\n",
       "      <td>cees1t</td>\n",
       "      <td>21899</td>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>Hi! My name is Alec Utgoff and I play Dr. Alex...</td>\n",
       "      <td>1659</td>\n",
       "      <td>You can follow me on Twitter @AlecUtgoff and I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42027</th>\n",
       "      <td>coloredneon</td>\n",
       "      <td>cibkdz</td>\n",
       "      <td>16975</td>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>Wills storyline doesnt seem to be about sexual...</td>\n",
       "      <td>813</td>\n",
       "      <td>I keep seeing posts and comments about Wills s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43275</th>\n",
       "      <td>brettcliffordgelman</td>\n",
       "      <td>ce4jk4</td>\n",
       "      <td>13026</td>\n",
       "      <td>2019-07-16</td>\n",
       "      <td>Im Brett Gelman aka Murray from Stranger Thing...</td>\n",
       "      <td>1225</td>\n",
       "      <td>Hi Reddit! Brett Gelman here. Im an actor and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45096</th>\n",
       "      <td>AndreyIvchenko</td>\n",
       "      <td>cbiolx</td>\n",
       "      <td>10260</td>\n",
       "      <td>2019-07-10</td>\n",
       "      <td>Hello Reddit family, it's Andrey Ivchenko here...</td>\n",
       "      <td>1114</td>\n",
       "      <td>Really excited to be here with you all today f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62402</th>\n",
       "      <td>lendmeahann</td>\n",
       "      <td>4y0nsh</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>A thought I've had since watching...</td>\n",
       "      <td>5</td>\n",
       "      <td>This isn't necessarily a theory, but I had thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33978</th>\n",
       "      <td>AnyAd8934</td>\n",
       "      <td>m4etve</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-13</td>\n",
       "      <td>Things I would like to see in season 4</td>\n",
       "      <td>4</td>\n",
       "      <td>Keith-yes,he works now at that video store,he ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45055</th>\n",
       "      <td>Pronay7</td>\n",
       "      <td>cbkeea</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-10</td>\n",
       "      <td>I think they will link the mysteries of the St...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62406</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>4y0en0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>The sherif</td>\n",
       "      <td>0</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55767</th>\n",
       "      <td>Jellysnake3486</td>\n",
       "      <td>7aws9n</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-05</td>\n",
       "      <td>Why did everyone keep saying 11 dies at the en...</td>\n",
       "      <td>4</td>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65507 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    AUTHOR      ID  SCORE CREATED_DATE  \\\n",
       "43395              Floker1  cdwiln  24310   2019-07-16   \n",
       "43139           Utgoffalec  cees1t  21899   2019-07-17   \n",
       "42027          coloredneon  cibkdz  16975   2019-07-27   \n",
       "43275  brettcliffordgelman  ce4jk4  13026   2019-07-16   \n",
       "45096       AndreyIvchenko  cbiolx  10260   2019-07-10   \n",
       "...                    ...     ...    ...          ...   \n",
       "62402          lendmeahann  4y0nsh      0   2016-08-16   \n",
       "33978            AnyAd8934  m4etve      0   2021-03-13   \n",
       "45055              Pronay7  cbkeea      0   2019-07-10   \n",
       "62406            [deleted]  4y0en0      0   2016-08-16   \n",
       "55767       Jellysnake3486  7aws9n      0   2017-11-05   \n",
       "\n",
       "                                                   TITLE NUM_COMMENTS  \\\n",
       "43395  Imagine Mike and Nancy finding out that all th...          718   \n",
       "43139  Hi! My name is Alec Utgoff and I play Dr. Alex...         1659   \n",
       "42027  Wills storyline doesnt seem to be about sexual...          813   \n",
       "43275  Im Brett Gelman aka Murray from Stranger Thing...         1225   \n",
       "45096  Hello Reddit family, it's Andrey Ivchenko here...         1114   \n",
       "...                                                  ...          ...   \n",
       "62402               A thought I've had since watching...            5   \n",
       "33978             Things I would like to see in season 4            4   \n",
       "45055  I think they will link the mysteries of the St...            0   \n",
       "62406                                         The sherif            0   \n",
       "55767  Why did everyone keep saying 11 dies at the en...            4   \n",
       "\n",
       "                                                SELFTEXT  \n",
       "43395                                                NaN  \n",
       "43139  You can follow me on Twitter @AlecUtgoff and I...  \n",
       "42027  I keep seeing posts and comments about Wills s...  \n",
       "43275  Hi Reddit! Brett Gelman here. Im an actor and ...  \n",
       "45096  Really excited to be here with you all today f...  \n",
       "...                                                  ...  \n",
       "62402  This isn't necessarily a theory, but I had thi...  \n",
       "33978  Keith-yes,he works now at that video store,he ...  \n",
       "45055                                                NaN  \n",
       "62406                                          [deleted]  \n",
       "55767                                          [removed]  \n",
       "\n",
       "[65507 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftry2.sort_values(by=['SCORE'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d5e8867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65507 entries, 0 to 65506\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   AUTHOR        65507 non-null  object\n",
      " 1   ID            65507 non-null  object\n",
      " 2   SCORE         65507 non-null  int64 \n",
      " 3   CREATED_DATE  65507 non-null  object\n",
      " 4   TITLE         65473 non-null  object\n",
      " 5   NUM_COMMENTS  65494 non-null  object\n",
      " 6   SELFTEXT      64029 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "dftry2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3e27ef",
   "metadata": {},
   "source": [
    "### Removing where the title or the selftext are null and removing the posts where the moderator for the Subreddit deleted/removed the post or the original author deleted/removed the post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "981939d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftry2.dropna(subset=['TITLE'], inplace = True)\n",
    "dftry2.dropna(subset=['SELFTEXT'], inplace = True)\n",
    "df_touse = dftry2[dftry2['SELFTEXT'] != \"[removed]\"].copy()\n",
    "df_to_use_fin = df_touse[df_touse['SELFTEXT'] != \"[deleted]\"].copy()\n",
    "df_to_use_fin['FULL_POSTS'] = df_to_use_fin['TITLE']+\".\"+\" \"+df_touse['SELFTEXT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0a29ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43302, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_use_fin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67075b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = df_to_use_fin[df_to_use_fin['ID'] == 'vow5wm']\n",
    "#check = dftry[dftry['ID'] == '7pzv67']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cb90f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>ID</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>CREATED_DATE</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>NUM_COMMENTS</th>\n",
       "      <th>SELFTEXT</th>\n",
       "      <th>FULL_POSTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15179</th>\n",
       "      <td>StrangerTesting</td>\n",
       "      <td>vow5wm</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>Stranger Things Season 4 Volume 2 Series Discu...</td>\n",
       "      <td>1</td>\n",
       "      <td># In this thread you can discuss the entirety ...</td>\n",
       "      <td>Stranger Things Season 4 Volume 2 Series Discu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AUTHOR      ID  SCORE CREATED_DATE  \\\n",
       "15179  StrangerTesting  vow5wm      1   2022-07-01   \n",
       "\n",
       "                                                   TITLE NUM_COMMENTS  \\\n",
       "15179  Stranger Things Season 4 Volume 2 Series Discu...            1   \n",
       "\n",
       "                                                SELFTEXT  \\\n",
       "15179  # In this thread you can discuss the entirety ...   \n",
       "\n",
       "                                              FULL_POSTS  \n",
       "15179  Stranger Things Season 4 Volume 2 Series Discu...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47220668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43302"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_to_use_fin.ID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7215aece",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_use_fin['CREATED_DATE'] = pd.to_datetime(df_to_use_fin['CREATED_DATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c056df61",
   "metadata": {},
   "source": [
    "### Only keeping posts from the release date of season 3 to current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "450d6137",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_use_fin = df_to_use_fin[df_to_use_fin['CREATED_DATE']> \"2019-07-04\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5327fcb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31643, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_use_fin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c93748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ed0567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04e7f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import nltk\n",
    "import en_core_web_sm\n",
    "#nlp = en_core_web_sm.load()\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcd7d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Cleaning Function\n",
    "import re\n",
    "\n",
    "def clean(text):\n",
    "    allowed_postags=[\"NOUN\", \"VERB\", \"ADJ\", \"ADV\", \"ADP\", \"PROPN\"]\n",
    "    \n",
    "    try: \n",
    "        text1 = re.sub(r\"http\\S+\", \"\", text)\n",
    "        #Convert text in lower case\n",
    "        text2 = text1.lower()\n",
    "        #text3 = text2.replace(\"[^a-zA-Z#]\", \" \")\n",
    "        #Removing Punctuations\n",
    "        punc_removed = text2.translate(str.maketrans('', '', string.punctuation))\n",
    "        doc= nlp(punc_removed)\n",
    "        text_out = [token.lemma_ for token in doc if token.is_stop == False and \\\n",
    "                    token.is_alpha and len(token)>2 and token.pos_ in allowed_postags\\\n",
    "                   ]\n",
    "        #txt = ' '.join(text_out)\n",
    "    except:\n",
    "        #txt = ''\n",
    "        text_out = ''\n",
    "    return text_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1825580",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_use_fin['token_lemma'] = df_to_use_fin['FULL_POSTS'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f439c06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/jacquelineskunda/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarity checked successfull\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def polarity(text):\n",
    "    pol = sid.polarity_scores(text)\n",
    "    return pol\n",
    "#polarity checking\n",
    "def joiner(text):\n",
    "    txt = ' '.join(text)\n",
    "    return txt\n",
    "df_to_use_fin['FULL_POSTS_CLEAN'] = df_to_use_fin['token_lemma'].apply(joiner)\n",
    "df_to_use_fin['polarity'] = df_to_use_fin['FULL_POSTS_CLEAN'].apply(polarity)\n",
    "df_to_use_fin['compound']  = df_to_use_fin['polarity'].apply(lambda score_dict: score_dict['compound'])\n",
    "\n",
    "df_to_use_fin['sentiment'] = df_to_use_fin['compound'].apply(lambda x: \"Positive\" if x>0 else(\"Negative\" if x<0 else \"Neutral\") )\n",
    "print(\"polarity checked successfull\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bcb6b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31643, 13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_use_fin.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b943840c",
   "metadata": {},
   "source": [
    "### Remove posts where the tokenized and lemmatized title+selftext, aka POSTS, have a length less than 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a40ceed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_use_fin['tok_len'] = df_to_use_fin['token_lemma'].apply(lambda x: len(x))\n",
    "df_to_use_fin.groupby(['tok_len'])['tok_len'].count()[2759]\n",
    "df_to_use_fin = df_to_use_fin[df_to_use_fin['tok_len']>=5].copy()\n",
    "df_to_use_fin.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e291885f",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08816373",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = []\n",
    "for i in range(len(df_to_use_fin)):\n",
    "    val.append(df_to_use_fin['token_lemma'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4e956da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x130bfa4c0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import models,corpora\n",
    "dictionary = corpora.Dictionary(val)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb61fd2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56308"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c5dc889",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in val]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9098c77a",
   "metadata": {},
   "source": [
    "### LDA first go - no tuning and 10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "66d0c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "lda_model =  gensim.models.LdaModel(bow_corpus, num_topics = 10, \n",
    "                                        passes = 8,alpha = 'auto',\n",
    "                                        random_state = 100,chunksize = 1000,\n",
    "                                        )\n",
    "#lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "60094a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPIC: 1 \n",
      "TOPIC WORDS : season, like, think, character, episode, time, know, feel, go, end\n",
      "\n",
      "TOPIC: 2 \n",
      "TOPIC WORDS : steve, nancy, robin, jonathan, dustin, suzie, scoop, barb, johnathan, noah\n",
      "\n",
      "TOPIC: 3 \n",
      "TOPIC WORDS : mind, flayer, power, upside, monster, theory, world, vecna, kill, control\n",
      "\n",
      "TOPIC: 4 \n",
      "TOPIC WORDS : wear, facility, police, magnet, club, holiday, red, shirt, blue, road\n",
      "\n",
      "TOPIC: 5 \n",
      "TOPIC WORDS : hopper, russian, know, theory, hawkin, joyce, find, american, brenner, alive\n",
      "\n",
      "TOPIC: 6 \n",
      "TOPIC WORDS : mike, billy, max, friend, love, girl, relationship, dustin, lucas, joyce\n",
      "\n",
      "TOPIC: 7 \n",
      "TOPIC WORDS : trailer, eddie, rainbow, victor, eddy, frame, metal, text, ultra, play\n",
      "\n",
      "TOPIC: 8 \n",
      "TOPIC WORDS : song, music, play, teaser, title, listen, soundtrack, david, harbour, coke\n",
      "\n",
      "TOPIC: 9 \n",
      "TOPIC WORDS : thing, strange, movie, watch, release, stranger, day, film, game, netflix\n",
      "\n",
      "TOPIC: 10 \n",
      "TOPIC WORDS : gate, upside, open, demogorgon, portal, close, light, kali, travel, world\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing Topics and Its keywords\n",
    "num_topics = 10\n",
    "for i in range(num_topics):\n",
    "    tt = lda_model.get_topic_terms(i,10)\n",
    "    topic = ', '.join([dictionary[pair[0]] for pair in tt])\n",
    "    print(\"TOPIC: {} \\nTOPIC WORDS : {}\".format(i+1, topic ))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e5d9ee09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.4501750424443521\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, \n",
    "                                     texts=df_to_use_fin['token_lemma'], \n",
    "                                     dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd747d62",
   "metadata": {},
   "source": [
    "### Finding ideal number of topics for LDA & Hyper parameter Tuning using ideal number of topics for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd62415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supporting function\n",
    "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=bow_corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=1000,\n",
    "                                           passes=8,\n",
    "                                           alpha=a,\n",
    "                                           eta=b)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, \n",
    "                                         texts=df_to_use_fin['token_lemma'], \n",
    "                                         dictionary=dictionary, \n",
    "                                         coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2705828d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-3847:\n",
      "Process SpawnPoolWorker-3848:\n",
      "Process SpawnPoolWorker-3849:\n",
      "Process SpawnPoolWorker-3846:\n",
      "Process SpawnPoolWorker-3844:\n",
      "Process SpawnPoolWorker-3843:\n",
      "Process SpawnPoolWorker-3845:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 109, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/gensim/models/ldamulticore.py\", line 341, in worker_e_step\n",
      "    chunk_no, chunk, w_state = input_queue.get()\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sk/13d9bc1s7wsbnd2qv8jmz03m0000gn/T/ipykernel_19370/2787654892.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m#get the coherence score for the given parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             cv = compute_coherence_values(corpus=bow_corpus, \n\u001b[0m\u001b[1;32m     37\u001b[0m                                           \u001b[0mdictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                                           k=k, a=a, b=b)\n",
      "\u001b[0;32m/var/folders/sk/13d9bc1s7wsbnd2qv8jmz03m0000gn/T/ipykernel_19370/1565151192.py\u001b[0m in \u001b[0;36mcompute_coherence_values\u001b[0;34m(corpus, dictionary, k, a, b)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_coherence_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     lda_model = gensim.models.LdaMulticore(corpus=bow_corpus,\n\u001b[0m\u001b[1;32m      5\u001b[0m                                            \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                            \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"auto-tuning alpha not implemented in LdaMulticore; use plain LdaModel.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         super(LdaMulticore, self).__init__(\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m             self.add_lifecycle_event(\n\u001b[1;32m    522\u001b[0m                 \u001b[0;34m\"created\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;31m# wait for all outstanding jobs to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mqueue_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                 \u001b[0mprocess_result_queue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreallen\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mprocess_result_queue\u001b[0;34m(force)\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0meval_every\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_updates\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mupdateafter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0meval_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_docs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlencorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training LDA model using %i processes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mlog_perplexity\u001b[0;34m(self, chunk, total_docs)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mcorpus_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0msubsample_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotal_docs\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0mperwordbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubsample_ratio\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msubsample_ratio\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcorpus_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m         logger.info(\n\u001b[1;32m    848\u001b[0m             \u001b[0;34m\"%.3f per-word bound, %.1f perplexity estimate based on a held-out corpus of %i documents with %i words\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mbound\u001b[0;34m(self, corpus, gamma, subsample_ratio)\u001b[0m\n\u001b[1;32m   1110\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bound: at document #%i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m                 \u001b[0mgammad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m                 \u001b[0mgammad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[1;32m    721\u001b[0m                 \u001b[0mphinorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpElogthetad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpElogbetad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0;31m# If gamma hasn't changed much, we're done.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m                 \u001b[0mmeanchange\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_difference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgammad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlastgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmeanchange\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma_threshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m                     \u001b[0mconverged\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#import tqdm\n",
    "#grid = {}\n",
    "#grid['Validation_Set'] = {}\n",
    "#Topics range\n",
    "min_topics = 4\n",
    "max_topics = 12\n",
    "step_size = 2\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "#Alpha parameter\n",
    "alpha = list('symmetric','asymmetric','auto')\n",
    "#Beta parameter\n",
    "beta = list('symmetric','asymmetric','auto')\n",
    "#Validation set len\n",
    "num_of_docs = len(bow_corpus)\n",
    "#corpus_sets = [gensim.utils.ClippedCorpus(bow_corpus, round(num_of_docs*0.75,0)),bow_corpus]\n",
    "corpus_title = '100% Corpus'\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "\n",
    "#iterate through validation corpuses\n",
    "#for i in range(len(num_of_docs)):\n",
    "#iterate through number of topics\n",
    "for k in topics_range:\n",
    "    #iterate through alpha values\n",
    "    for a in alpha:\n",
    "        #iterare through beta values\n",
    "        for b in beta:\n",
    "            #get the coherence score for the given parameters\n",
    "            cv = compute_coherence_values(corpus=bow_corpus, \n",
    "                                          dictionary=dictionary, \n",
    "                                          k=k, a=a, b=b)\n",
    "            #Save the model results\n",
    "            model_results['Validation_Set'].append(corpus_title)\n",
    "            model_results['Topics'].append(k)\n",
    "            model_results['Alpha'].append(a)\n",
    "            model_results['Beta'].append(b)\n",
    "            model_results['Coherence'].append(cv)\n",
    "                    \n",
    "\n",
    "pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
    "#pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072f06fd",
   "metadata": {},
   "source": [
    "### Running Final LDA model with ideal tuned parameters and ideal topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f3976",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_optimals = pd.read_csv(\"lda_tuning_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c086345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_final = gensim.models.LdaMulticore(corpus=bow_corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=#8, \n",
    "                                           random_state=#100,\n",
    "                                           chunksize=#100,\n",
    "                                           passes=#10,\n",
    "                                           alpha=#0.01,\n",
    "                                           eta=#0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "62384da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pyLDAvis/_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  default_term_info = default_term_info.sort_values(\n",
      "/usr/local/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el564951465521284197215926\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el564951465521284197215926_data = {\"mdsDat\": {\"x\": [-0.1796773507501708, 0.10214763659846672, -0.21966487713881422, -0.1302654622379861, -0.11645455980451938, 0.11865097794678675, -0.11784065990709232, 0.19709188862184945, 0.19707203224790246, 0.14894037442357752], \"y\": [0.046998538537937694, 0.14780994253122834, -0.1275651474762462, -0.12777710471153023, 0.16173409439081665, 0.18869613054755907, -0.02491126888296857, -0.19579503116784006, -0.18523022055317237, 0.11604006678421531], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [11.86918415211355, 11.648618638105267, 11.285930079609988, 10.471996368373693, 10.300078389552864, 9.549113323038192, 9.153812173300434, 9.001450373637953, 8.988822972933164, 7.730993529334897]}, \"tinfo\": {\"Term\": [\"spoiler\", \"thing\", \"strange\", \"season\", \"think\", \"question\", \"theory\", \"episode\", \"hopper\", \"watch\", \"character\", \"steve\", \"end\", \"know\", \"time\", \"mike\", \"song\", \"notice\", \"finish\", \"nancy\", \"demogorgon\", \"feel\", \"dustin\", \"play\", \"favorite\", \"scene\", \"find\", \"jonathan\", \"look\", \"monster\", \"character\", \"favorite\", \"prediction\", \"final\", \"moment\", \"main\", \"speculation\", \"shit\", \"expect\", \"eggo\", \"villain\", \"rank\", \"early\", \"arc\", \"timeline\", \"wow\", \"development\", \"fuck\", \"guess\", \"case\", \"bluray\", \"annoying\", \"member\", \"trope\", \"ride\", \"curious\", \"player\", \"wanna\", \"short\", \"holy\", \"amazing\", \"death\", \"love\", \"bad\", \"big\", \"rewatche\", \"wish\", \"discussion\", \"season\", \"good\", \"new\", \"scene\", \"want\", \"scary\", \"different\", \"cast\", \"small\", \"finish\", \"series\", \"thing\", \"strange\", \"opinion\", \"unpopular\", \"poster\", \"stranger\", \"official\", \"anthology\", \"comic\", \"alexei\", \"experience\", \"disappoint\", \"stephen\", \"spinoff\", \"goonie\", \"hide\", \"con\", \"dyer\", \"build\", \"youtube\", \"government\", \"twin\", \"coincidence\", \"merch\", \"font\", \"pay\", \"predict\", \"cop\", \"shower\", \"silence\", \"movie\", \"super\", \"king\", \"netflix\", \"plan\", \"set\", \"influence\", \"game\", \"murray\", \"chapter\", \"series\", \"book\", \"watch\", \"good\", \"fan\", \"story\", \"want\", \"love\", \"new\", \"theory\", \"end\", \"upside\", \"spoiler\", \"possible\", \"power\", \"vibe\", \"upsidedown\", \"potential\", \"minor\", \"discuss\", \"grow\", \"shadow\", \"jump\", \"demogorgan\", \"terry\", \"heart\", \"alert\", \"camera\", \"funny\", \"general\", \"warning\", \"reddit\", \"subject\", \"stick\", \"xman\", \"til\", \"join\", \"community\", \"lack\", \"volume\", \"work\", \"write\", \"monster\", \"season\", \"test\", \"happen\", \"return\", \"barb\", \"discussion\", \"vecna\", \"want\", \"world\", \"think\", \"hopper\", \"joyce\", \"come\", \"year\", \"rewatch\", \"wait\", \"date\", \"jim\", \"gon\", \"bob\", \"weird\", \"live\", \"daughter\", \"random\", \"kind\", \"letter\", \"able\", \"intro\", \"enjoy\", \"benny\", \"shirt\", \"father\", \"synth\", \"blood\", \"poor\", \"win\", \"walk\", \"petition\", \"explanation\", \"great\", \"release\", \"future\", \"byer\", \"wall\", \"clarke\", \"wonder\", \"guy\", \"people\", \"barb\", \"season\", \"happen\", \"die\", \"question\", \"time\", \"mind\", \"start\", \"flayer\", \"video\", \"second\", \"today\", \"quick\", \"parallel\", \"connection\", \"answer\", \"stupid\", \"mall\", \"drop\", \"travel\", \"dead\", \"free\", \"dragon\", \"dungeon\", \"learn\", \"bug\", \"wood\", \"meme\", \"silent\", \"starcourt\", \"retro\", \"target\", \"recommend\", \"class\", \"watch\", \"finish\", \"entire\", \"vecna\", \"ask\", \"game\", \"story\", \"theme\", \"episode\", \"season\", \"series\", \"amp\", \"day\", \"dampd\", \"song\", \"play\", \"need\", \"soundtrack\", \"help\", \"like\", \"explain\", \"hear\", \"credit\", \"find\", \"actor\", \"boy\", \"score\", \"halloween\", \"minute\", \"issue\", \"list\", \"young\", \"track\", \"car\", \"effect\", \"body\", \"hey\", \"maxs\", \"dislike\", \"listen\", \"costume\", \"suggestion\", \"gif\", \"order\", \"know\", \"run\", \"episode\", \"version\", \"remind\", \"scene\", \"music\", \"try\", \"look\", \"guy\", \"want\", \"good\", \"feel\", \"talk\", \"trailer\", \"finale\", \"plot\", \"hole\", \"billy\", \"lab\", \"dog\", \"sad\", \"barbara\", \"kali\", \"confused\", \"genre\", \"sense\", \"bit\", \"fun\", \"dumb\", \"late\", \"team\", \"mention\", \"type\", \"pick\", \"christmas\", \"stand\", \"agree\", \"share\", \"fact\", \"style\", \"speak\", \"believe\", \"idea\", \"light\", \"hawkin\", \"house\", \"let\", \"vol\", \"leave\", \"die\", \"kid\", \"season\", \"thought\", \"scene\", \"new\", \"mike\", \"dustin\", \"max\", \"reference\", \"hope\", \"hate\", \"duffer\", \"wheeler\", \"brenner\", \"brother\", \"favourite\", \"mom\", \"luca\", \"stop\", \"awesome\", \"bother\", \"storyline\", \"hour\", \"meet\", \"alive\", \"request\", \"erica\", \"man\", \"suzie\", \"gay\", \"pop\", \"star\", \"nancys\", \"appreciate\", \"millie\", \"creature\", \"lucas\", \"fan\", \"film\", \"robin\", \"love\", \"steve\", \"notice\", \"nancy\", \"jonathan\", \"miss\", \"real\", \"eddie\", \"tell\", \"detail\", \"gate\", \"lose\", \"problem\", \"life\", \"harrington\", \"wrong\", \"hop\", \"deserve\", \"person\", \"deal\", \"forget\", \"bring\", \"hero\", \"cover\", \"room\", \"wear\", \"similarity\", \"jacket\", \"fucking\", \"hot\", \"recommendation\", \"fight\", \"look\", \"july\", \"friend\", \"open\", \"world\", \"lot\", \"reason\", \"point\", \"cool\", \"sister\", \"girl\", \"people\", \"demogorgon\", \"russian\", \"binge\", \"similar\", \"egg\", \"mean\", \"american\", \"chief\", \"foreshadow\", \"easter\", \"understand\", \"horror\", \"ryder\", \"sound\", \"realize\", \"david\", \"teaser\", \"school\", \"thread\", \"harbour\", \"comment\", \"high\", \"joke\", \"catch\", \"eat\", \"fate\", \"chance\", \"significance\", \"portal\", \"check\", \"week\", \"post\", \"monster\", \"food\", \"music\", \"day\", \"title\", \"sub\", \"interesting\", \"series\", \"book\"], \"Freq\": [6673.0, 5135.0, 4279.0, 7815.0, 2583.0, 2214.0, 2102.0, 2372.0, 1438.0, 1626.0, 1391.0, 1028.0, 918.0, 887.0, 826.0, 750.0, 720.0, 638.0, 844.0, 569.0, 524.0, 558.0, 515.0, 524.0, 559.0, 928.0, 509.0, 487.0, 608.0, 605.0, 1390.3382747857318, 558.2489471344309, 351.4061585724151, 275.5546902033611, 249.86008833227623, 152.5634350775939, 114.763876192132, 102.79193065417236, 101.71243769873367, 100.10547969074196, 95.55728928534036, 77.44097174706656, 76.18646738605995, 73.92385064289296, 72.32134624209806, 71.66152788167886, 70.50960128327986, 59.92550066701987, 56.92734985329781, 54.94441964208965, 54.55979032852907, 51.58277988867319, 45.54201678169691, 43.4257679487474, 43.01539108146189, 41.153888580169145, 40.60757358030831, 39.60748646668284, 39.33440794697858, 38.25924135281677, 135.32455274952483, 156.93116444182326, 551.9727220343494, 294.8615468950406, 230.93296856792634, 185.93319491665318, 105.56331168745615, 267.95175526441056, 3875.8420602688, 494.42930886591955, 470.0107992843224, 581.2671548575483, 427.3887165657169, 111.95326831319366, 112.36486059840381, 157.73425293247868, 91.57352667833001, 162.1345923545273, 152.96549708218194, 5135.033233023198, 4278.161044139226, 410.76847320307513, 231.36347513412468, 199.60696910363293, 148.7572485428494, 100.61623791572488, 97.57555041352941, 91.82422377684077, 76.7000213001221, 72.2783618883388, 71.0821411023814, 62.7959823697129, 48.74504426953922, 48.561856315334644, 43.50276397169584, 42.933632500621705, 42.411068837181986, 39.45021063200213, 39.1142799242565, 35.65946018050357, 35.48590961796589, 33.66966177017874, 33.421535537896936, 31.77223030916541, 31.299645004834726, 29.240621442704168, 28.055017720712254, 27.59485810612904, 27.498434667563643, 198.22970918315005, 75.33128775832574, 61.97560694000895, 201.33312154996574, 56.97821026679537, 95.4369107138504, 61.5174002106451, 159.83323838175113, 59.51832613380977, 64.11447487103665, 183.0701868286602, 80.3404577241297, 215.54700822059314, 146.90900524372844, 95.28007702104055, 84.38204734658306, 97.10748667365371, 75.29476213003323, 64.86091195627203, 2101.1854538818043, 917.7637414539938, 371.4237027784776, 6657.180304142772, 286.63869642585865, 236.31679403099412, 146.87292185038172, 137.54366665132423, 121.53476175780737, 86.11602981553291, 69.80289003399608, 62.541197110133034, 56.52046711307862, 55.51613317569595, 52.478715804514856, 51.053659896370604, 50.80478557786705, 48.741950375192175, 45.96451364824022, 42.93119752356109, 42.355445931720986, 40.580999702300595, 36.523344068543025, 35.36038409656739, 32.6489261205637, 32.373389527623885, 31.935042210120123, 28.692101488674243, 27.920641584611968, 25.617687369419684, 103.7681535669275, 137.89526405235577, 73.76870778575837, 250.8536476546188, 1294.4981871290852, 41.64704425719154, 145.7544956578181, 44.927665963156784, 82.3339712712302, 83.48001725203697, 78.76407609123893, 83.7065078599779, 56.88874903573922, 2582.868109843624, 1437.4613040131126, 355.6112072955096, 399.1564385524897, 213.11399179264563, 170.87541014207477, 165.34025528717873, 152.37235295916443, 146.56794290041626, 143.64692345462396, 135.28657105417926, 113.12517835095302, 113.12820569120797, 106.7099656186171, 97.06314071842404, 96.31037824029784, 94.873839477579, 83.60676039377329, 82.53658399981087, 82.51248141614421, 80.01590901070077, 66.35213652219039, 64.98025586297307, 62.4192537594949, 59.80540095376534, 58.96945243037268, 58.18595586748427, 58.15681674971059, 57.86496876104022, 56.112676861218354, 198.4230605635143, 341.8466421843932, 139.72812053400935, 235.66363507665068, 86.25568311685527, 77.84422208975346, 116.81358596730529, 255.5682811145795, 228.23252902587015, 163.24659012518063, 926.0319492031832, 126.70694940560102, 99.28616080021615, 2213.4299443505797, 825.6742521388645, 409.87011659943323, 360.0486294631388, 301.8438121534428, 194.3266918718425, 170.8166731058941, 141.83822873311874, 136.94269813868667, 123.31326778239406, 107.09736433716213, 98.14867083062414, 76.79652767265608, 76.57982245022949, 68.97078545875792, 67.70519680260774, 65.12470945673938, 61.03931796362034, 58.665167406093175, 53.62742591330594, 52.26202917994454, 50.4113836390276, 50.21431485236242, 48.05302371541601, 47.6551583797024, 47.31576827066868, 45.43844961892979, 42.642696370533564, 42.03156418770702, 41.814759964440825, 1410.1778288285884, 681.8806806692314, 111.03386618297789, 257.5320111277393, 98.79345568346415, 242.3444294033917, 163.35801077431975, 110.70535093540133, 533.6059961197153, 1028.5830221773224, 183.31831635930507, 91.0903755098255, 83.17624839251565, 67.80290301583987, 719.602665723009, 523.6474755770847, 401.0709269839588, 380.67938263545807, 352.62253256866853, 224.0265560186395, 206.74263673642014, 141.53482655166502, 139.9676702086023, 506.65590575584457, 132.60810012251602, 132.10048464856223, 119.92169523599715, 109.71956886654581, 108.59278649177698, 108.54529947297516, 107.7714926416195, 100.97288502830747, 99.48038341863912, 93.11214544628791, 76.68948084182318, 72.0944234016004, 67.35417260103573, 64.88475584052156, 60.3829285643306, 59.205425591424344, 56.978809689755636, 54.938632935499896, 54.24536905842481, 50.13108061743177, 858.3887380329088, 88.30318461495024, 1838.4491872623273, 72.4039503702728, 153.51436252316185, 237.13771767369167, 151.6065789560265, 81.72758807254114, 115.48664349115136, 97.92287839206496, 86.81791266737719, 86.87126672641456, 557.237672378784, 451.5334562005765, 413.97919742338604, 406.3743524106369, 376.7362642392476, 176.96589995357036, 176.48982897821242, 167.95464834215645, 122.83307959002266, 107.56138839587337, 107.55379475858197, 95.82996325490582, 95.46376991005222, 94.4595147622385, 93.50102447660343, 93.49707876310889, 90.52368923924116, 86.40131200652891, 84.94495118607459, 84.27766538505364, 74.0709979437444, 70.51536188139265, 65.82831447030846, 65.28203957371728, 63.80487408210989, 61.37271733381542, 61.210361037038794, 61.557583824559245, 59.84425079883118, 57.433426621608454, 87.16170446371544, 276.3244207121801, 169.884366190951, 324.0650633914977, 146.46338243333372, 183.75677743533728, 105.75563227669491, 132.39139794790572, 189.82787014596795, 209.07626526707185, 673.5561150393444, 107.46451199285279, 109.64538837986824, 92.01041107296572, 749.4007370444909, 514.2787060777372, 413.575320084685, 357.91592068546004, 298.9304963275042, 280.1366543871165, 262.87984014058134, 237.24978288470163, 223.5544580296203, 205.40860249476222, 160.24664409385628, 157.58841170661842, 153.99335299355198, 141.90614772238385, 126.12913892005308, 118.65655734882046, 118.30787299157848, 110.66323866413461, 105.90896019720479, 101.67064033997765, 101.535537796612, 99.72617532076332, 98.03403260335298, 96.6273356044132, 96.31580111894792, 86.08128431167334, 85.9211578489454, 85.20434900987172, 83.3116422408916, 79.60404909896951, 82.87511460927114, 114.32910974475821, 307.084993011955, 147.8812340681182, 161.15768779638447, 104.86288050428801, 1027.8064571824375, 637.7456707403381, 568.8666064548778, 486.80466604957275, 320.3086820664354, 248.6957084628472, 215.70172612021463, 189.61539668702096, 143.6605930911272, 140.8394222981328, 138.83404328273727, 138.23791382557175, 160.3801176382571, 114.38376349088843, 106.66264489038551, 102.74738268079462, 102.18038911896917, 91.33102971901826, 90.85440794205465, 82.5616901283872, 82.27177999459967, 75.84365314731222, 69.26668334563695, 72.46729202016662, 68.05077145422672, 65.64069325752686, 60.86800232136227, 59.125251767680595, 59.120154315188394, 58.20729162350714, 78.18301831335096, 492.22484643359354, 61.2414920673297, 138.90528799032066, 112.09093334747084, 135.740268439775, 139.03334237704794, 96.90251870915388, 103.74438324542415, 91.60092221668253, 83.56562243089076, 84.20668523394909, 84.6123414337135, 523.9388250734651, 277.35965181481015, 230.90551308622346, 221.29881142764262, 169.88824806469137, 158.33742905802168, 154.61686676655074, 140.6197705938918, 137.3360345283871, 134.12370242005142, 130.49258370221006, 125.1429685934825, 118.24775389954027, 113.20927073098433, 105.82314525754293, 104.59563966980309, 100.16299267002269, 99.68781225316593, 90.41385463546563, 88.66084518875279, 89.22234825699975, 82.50516903007188, 77.12032065269321, 75.46117894410315, 66.79050817041873, 66.0987837643376, 64.74537811571041, 64.18905943660468, 61.45778948319227, 61.85954248780173, 81.47757966087082, 302.08506108469334, 353.47190315223537, 78.07452262147056, 234.01445464242394, 170.2515211269648, 118.17030244103562, 98.72212117504581, 94.24631284957032, 104.86025500707353, 83.1993455893411], \"Total\": [6673.0, 5135.0, 4279.0, 7815.0, 2583.0, 2214.0, 2102.0, 2372.0, 1438.0, 1626.0, 1391.0, 1028.0, 918.0, 887.0, 826.0, 750.0, 720.0, 638.0, 844.0, 569.0, 524.0, 558.0, 515.0, 524.0, 559.0, 928.0, 509.0, 487.0, 608.0, 605.0, 1391.2030228771966, 559.1132826999356, 352.27046809825487, 276.41904856552344, 250.7244720647584, 153.42777247250626, 115.6771738782909, 103.65633633040738, 102.57680894676976, 100.97000899060437, 96.42161633766017, 78.30527904948224, 77.05086196664902, 74.78820974940558, 73.18569906376422, 72.52592232002374, 71.37393692272978, 60.789849050559056, 57.80628815427645, 55.808830799397306, 55.42416611697451, 52.447133726907616, 46.40636954042007, 44.290351598681156, 43.87988494882396, 42.018241777016215, 41.472052528703244, 40.47184870319396, 40.198876052542694, 39.12359149754818, 151.9233611262109, 179.80849353659414, 732.7939658720437, 370.23028625612415, 282.65510300037084, 228.65776447880333, 121.21186482618228, 352.21657974802577, 7815.176100030329, 734.2153907144506, 699.4624565248919, 928.7225174798842, 707.3256771567738, 135.87025046776034, 140.62203967388334, 262.4657393013456, 122.92354107057287, 844.7842050104089, 737.0775820110586, 5135.907994422602, 4279.035788093554, 411.64320828036705, 232.2381975762151, 200.48175802920875, 149.6319890813643, 101.49104403894162, 98.4504021209531, 92.700207654838, 77.5748414933743, 73.15319429629608, 71.95690061806816, 63.670828822744966, 49.61978238699675, 49.43670472188375, 44.377677223680415, 43.80837298236283, 43.285818643397384, 40.325041630187776, 39.9890655046276, 36.534359551226764, 36.360674173556426, 34.5444414373071, 34.29626467990174, 32.64702838016404, 32.17439874652183, 30.11543778749698, 28.929807998921657, 28.472192402429112, 28.373247530400313, 310.2261099915718, 100.19565102921798, 78.76913764255163, 352.80172599629975, 73.15687504792649, 157.352839254234, 86.47168741293275, 402.95701732646893, 88.83161115486003, 103.31718323641532, 737.0775820110586, 164.31980962761872, 1626.504214254027, 734.2153907144506, 403.13144269851375, 309.042555105591, 707.3256771567738, 732.7939658720437, 699.4624565248919, 2102.0730016212237, 918.6513397820501, 372.31591545374, 6673.988850882532, 287.5262579995133, 237.20434715822995, 147.76054457060724, 138.43124170910264, 122.42245506414365, 87.00361248147209, 70.69047373070991, 63.42886321730487, 57.40803991468827, 56.40370964918663, 53.366261765197876, 51.941208170540186, 51.692373574265105, 49.62948253326643, 46.85221659272824, 43.81879828265071, 43.24303048056645, 41.468647648023776, 37.411001148197364, 36.24791457460055, 33.536661794819764, 33.26099412366702, 32.822853518243654, 29.579732432857803, 28.808352742448218, 26.5497370161956, 120.99033567471052, 171.06640773405573, 94.43605170630035, 605.1184061060285, 7815.176100030329, 48.638199153824175, 572.5923932480556, 63.14606887108035, 310.2252256823931, 352.21657974802577, 390.9307209190386, 707.3256771567738, 193.41337922027947, 2583.7402682321776, 1438.3302774704528, 356.4801651827903, 400.5665680504283, 213.98298741822313, 171.74440558260628, 166.2095379280163, 153.24131233622447, 147.4369042344005, 144.51597970417725, 136.15554823133925, 113.99414968520752, 113.9973776222641, 107.57892413063739, 97.93209768150057, 97.1794132972153, 95.7428063921193, 84.47604294903935, 83.40560996565236, 83.38162688707384, 80.88494737405084, 67.22115544035093, 65.84920501038256, 63.28844971776058, 60.67447290917385, 59.838446404477864, 59.05497947711643, 59.025820836036594, 58.7340053283168, 56.98163337446341, 209.53037426228408, 397.53944946119304, 164.30882114810973, 312.3503977656481, 94.65369533020413, 85.61282444934432, 147.28403416773276, 433.4093444070138, 473.2107988683152, 310.2252256823931, 7815.176100030329, 572.5923932480556, 289.8809156016626, 2214.3017029985895, 826.7460813795145, 410.7418554984218, 360.9204049717622, 302.71554411217016, 195.19859310686905, 171.68852563169855, 142.71001263806173, 137.8144676361584, 124.18506595325485, 107.96914132615822, 99.05453707150855, 77.66830496061597, 77.45161961839555, 69.84606275087269, 68.57694242583499, 65.99655524130573, 61.911113878827486, 59.53693720729984, 54.499192693196925, 53.13382787122118, 51.28315065732452, 51.08628438254519, 48.92480661213039, 48.527064174170306, 48.18752169153501, 46.31048523244891, 43.51447258991582, 42.9033811747461, 42.68657637445495, 1626.504214254027, 844.7842050104089, 121.43801210601994, 390.9307209190386, 122.69860410968326, 402.95701732646893, 309.042555105591, 173.4459948269974, 2372.9083864057343, 7815.176100030329, 737.0775820110586, 261.4741864354738, 315.1383402072543, 175.2309743288879, 720.479778626691, 524.5246230566346, 401.94931079824994, 381.5565307289656, 353.49965630979045, 224.90369488378397, 207.6197836721701, 142.41197539803932, 140.84534777206315, 509.9588304755637, 133.48525713162437, 132.97765151998476, 120.7988519020818, 110.5967250907047, 109.46993517001643, 109.42245503908971, 108.6486481223429, 101.85008630476308, 100.35752152184482, 93.9893215261897, 77.5666582477923, 72.97162356300134, 68.23131937293071, 65.76188470394493, 61.26005444330846, 60.08255226282469, 57.855943441057825, 55.81586145052369, 55.12262922226447, 51.00825081724111, 887.5353741615078, 91.53740045173546, 2372.9083864057343, 80.85653828229793, 237.49650061223406, 928.7225174798842, 386.40425502013636, 142.5262603928694, 608.4854286099884, 433.4093444070138, 707.3256771567738, 734.2153907144506, 558.1028026336938, 452.3986549632267, 414.84432509665737, 407.2394858788636, 377.6013637237072, 177.83098310748824, 177.35520885081644, 168.81979876335652, 123.69818316431447, 108.42653005048606, 108.41904547930916, 96.69506124216728, 96.32886526809376, 95.32477004513963, 94.3661256398517, 94.36221496975263, 91.39920945783548, 87.26643537359332, 85.81009253028482, 85.1427929744009, 74.93614044737554, 71.38057271178003, 66.69344390730157, 66.14717412961785, 64.67002522472269, 62.23785900119897, 62.07644591553679, 62.43963618764227, 60.70944977884953, 58.298581798326424, 89.29473049335675, 313.7788093961838, 187.9319845137947, 388.4679199569194, 167.6319114807336, 225.55790602932993, 119.75475811397529, 163.69740563614383, 289.8809156016626, 503.6598346345763, 7815.176100030329, 160.23404291459823, 928.7225174798842, 699.4624565248919, 750.259518799048, 515.1375052322594, 414.4907395554758, 358.77474504832736, 299.78933096378694, 280.9954351318114, 263.73863523347717, 238.1085600156798, 224.41326183843051, 206.26738615530516, 161.10542383428708, 158.44724297630512, 154.85213379258133, 142.76495656444007, 126.98802956979054, 119.5153570240764, 119.16667025972696, 111.52210021385105, 106.76776341356141, 102.52953046615778, 102.39439946988385, 100.58495429161056, 98.89283965432436, 97.48611708050045, 97.1745709093971, 86.9400804848608, 86.77996059174065, 86.06314564856226, 84.17050602915536, 80.46282901555547, 83.79526642940789, 116.73594952689601, 403.13144269851375, 206.4521987336164, 245.4221305502048, 732.7939658720437, 1028.6703717650234, 638.6096179039744, 569.7305230102642, 487.668592918651, 321.1726289729756, 249.56022094905668, 216.56564347763302, 190.50480785646067, 144.5245600262946, 141.70334006655915, 139.69798172738214, 139.10185473063103, 161.39362232005328, 115.24767306915697, 107.52656595318123, 103.6113369000868, 103.0443256544456, 92.19497488044111, 91.71838163691025, 83.42561117568906, 83.13842739863124, 76.70758712362817, 70.13066521670594, 73.38703721983099, 68.9147279351948, 66.50465277850758, 61.73192415202073, 59.98920935853261, 59.98406306327081, 59.07130140805096, 80.70056249016689, 608.4854286099884, 62.3409639352865, 173.94587121361326, 142.2381140312252, 193.41337922027947, 211.46234243072794, 131.0442560186727, 150.15052954123684, 125.47207340366104, 112.49239805191694, 123.4773271423164, 473.2107988683152, 524.81124932256, 278.23207637900975, 231.77798843128045, 222.17132781004713, 170.76065961145846, 159.2103038676287, 155.48929763071996, 141.4923659315267, 138.20849476577814, 134.99611049090234, 131.3650229639597, 126.01542790392423, 119.12024440384755, 114.08172235853462, 106.69557098628435, 105.46807768908664, 101.03543056832767, 100.56022931226782, 91.28630471382515, 89.53327437367244, 90.11754083281306, 83.37759189200588, 77.99291254558396, 76.33361440638085, 67.662989405403, 66.97120749796325, 65.6178276357279, 65.06147667687422, 62.33020065502639, 62.73986489886284, 82.68074106256198, 363.56003157242037, 605.1184061060285, 84.77603822012811, 386.40425502013636, 315.1383402072543, 193.91298024291734, 141.18605694361872, 134.19119022411485, 737.0775820110586, 164.31980962761872], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.6067, -3.5192, -3.9821, -4.2252, -4.3231, -4.8164, -5.1011, -5.2113, -5.2219, -5.2378, -5.2843, -5.4945, -5.5108, -5.541, -5.5629, -5.5721, -5.5883, -5.7509, -5.8022, -5.8377, -5.8447, -5.9008, -6.0254, -6.073, -6.0825, -6.1267, -6.1401, -6.165, -6.1719, -6.1996, -4.9363, -4.7882, -3.5305, -4.1575, -4.4019, -4.6186, -5.1847, -4.2532, -1.5815, -3.6406, -3.6913, -3.4788, -3.7863, -5.1259, -5.1223, -4.7831, -5.3269, -4.7556, -4.8138, -1.2814, -1.464, -3.8072, -4.3813, -4.5289, -4.823, -5.214, -5.2446, -5.3054, -5.4854, -5.5447, -5.5614, -5.6854, -5.9387, -5.9424, -6.0524, -6.0656, -6.0779, -6.1502, -6.1588, -6.2513, -6.2561, -6.3087, -6.3161, -6.3667, -6.3817, -6.4497, -6.4911, -6.5076, -6.5111, -4.5358, -5.5034, -5.6985, -4.5203, -5.7826, -5.2668, -5.7059, -4.7511, -5.739, -5.6646, -4.6154, -5.439, -4.4521, -4.8355, -5.2684, -5.3899, -5.2494, -5.5039, -5.653, -2.1434, -2.9717, -3.8763, -0.9902, -4.1354, -4.3285, -4.8041, -4.8697, -4.9934, -5.3379, -5.548, -5.6578, -5.759, -5.777, -5.8332, -5.8608, -5.8656, -5.9071, -5.9658, -6.034, -6.0475, -6.0903, -6.1957, -6.228, -6.3078, -6.3163, -6.3299, -6.437, -6.4643, -6.5504, -5.1515, -4.8671, -5.4927, -4.2688, -2.6278, -6.0644, -4.8117, -5.9886, -5.3829, -5.369, -5.4272, -5.3663, -5.7525, -1.8621, -2.4482, -3.8449, -3.7294, -4.357, -4.5778, -4.6108, -4.6925, -4.7313, -4.7514, -4.8114, -4.9903, -4.9903, -5.0487, -5.1434, -5.1512, -5.1662, -5.2927, -5.3055, -5.3058, -5.3366, -5.5238, -5.5447, -5.5849, -5.6277, -5.6418, -5.6551, -5.6556, -5.6607, -5.6914, -4.4284, -3.8844, -4.7791, -4.2564, -5.2615, -5.3641, -4.9582, -4.1753, -4.2884, -4.6235, -2.8879, -4.8769, -5.1208, -1.9999, -2.986, -3.6864, -3.816, -3.9923, -4.4327, -4.5616, -4.7475, -4.7827, -4.8875, -5.0285, -5.1157, -5.3611, -5.3639, -5.4685, -5.4871, -5.5259, -5.5907, -5.6304, -5.7202, -5.746, -5.782, -5.7859, -5.8299, -5.8382, -5.8454, -5.8859, -5.9494, -5.9638, -5.969, -2.4508, -3.1774, -4.9924, -4.1511, -5.1092, -4.2119, -4.6063, -4.9954, -3.4226, -2.7663, -4.491, -5.1904, -5.2813, -5.4856, -3.0478, -3.3657, -3.6324, -3.6846, -3.7611, -4.2148, -4.2951, -4.674, -4.6851, -3.3987, -4.7391, -4.743, -4.8397, -4.9286, -4.9389, -4.9394, -4.9465, -5.0117, -5.0266, -5.0927, -5.2868, -5.3486, -5.4166, -5.4539, -5.5258, -5.5455, -5.5838, -5.6203, -5.633, -5.7119, -2.8715, -5.1458, -2.1099, -5.3443, -4.5927, -4.1579, -4.6052, -5.2231, -4.8774, -5.0423, -5.1627, -5.1621, -3.2613, -3.4716, -3.5584, -3.577, -3.6527, -4.4083, -4.411, -4.4606, -4.7734, -4.9062, -4.9063, -5.0217, -5.0255, -5.0361, -5.0463, -5.0463, -5.0786, -5.1252, -5.1422, -5.1501, -5.2792, -5.3284, -5.3972, -5.4055, -5.4284, -5.4673, -5.4699, -5.4643, -5.4925, -5.5336, -5.1165, -3.9627, -4.4491, -3.8033, -4.5975, -4.3706, -4.9231, -4.6985, -4.3381, -4.2416, -3.0717, -4.9071, -4.887, -5.0623, -2.9482, -3.3247, -3.5426, -3.6872, -3.8673, -3.9322, -3.9958, -4.0984, -4.1578, -4.2425, -4.4908, -4.5075, -4.5306, -4.6123, -4.7302, -4.7912, -4.7942, -4.861, -4.9049, -4.9457, -4.9471, -4.965, -4.9822, -4.9966, -4.9998, -5.1122, -5.114, -5.1224, -5.1449, -5.1904, -5.1501, -4.8284, -3.8403, -4.5711, -4.4851, -4.9148, -2.6309, -3.1081, -3.2224, -3.3782, -3.7968, -4.0498, -4.1922, -4.3211, -4.5986, -4.6184, -4.6328, -4.6371, -4.4885, -4.8265, -4.8964, -4.9338, -4.9393, -5.0516, -5.0568, -5.1525, -5.156, -5.2374, -5.3281, -5.2829, -5.3458, -5.3819, -5.4574, -5.4864, -5.4865, -5.5021, -5.207, -3.3671, -5.4512, -4.6323, -4.8468, -4.6553, -4.6313, -4.9924, -4.9241, -5.0486, -5.1404, -5.1328, -5.128, -3.1539, -3.79, -3.9733, -4.0158, -4.2802, -4.3506, -4.3744, -4.4693, -4.4929, -4.5166, -4.544, -4.5859, -4.6425, -4.6861, -4.7535, -4.7652, -4.8085, -4.8133, -4.9109, -4.9305, -4.9242, -5.0025, -5.07, -5.0917, -5.2138, -5.2242, -5.2449, -5.2535, -5.297, -5.2905, -5.015, -3.7046, -3.5475, -5.0577, -3.9599, -4.278, -4.6432, -4.823, -4.8694, -4.7627, -4.9941], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 2.1306, 2.1297, 2.1288, 2.1281, 2.1278, 2.1256, 2.1233, 2.1229, 2.1228, 2.1226, 2.1222, 2.1201, 2.1199, 2.1196, 2.1193, 2.1192, 2.119, 2.1169, 2.1159, 2.1156, 2.1155, 2.1146, 2.1124, 2.1115, 2.1113, 2.1104, 2.1102, 2.1096, 2.1095, 2.1089, 2.0155, 1.9951, 1.8479, 1.9036, 1.9291, 1.9244, 1.993, 1.8578, 1.4299, 1.7358, 1.7337, 1.6626, 1.6274, 1.9376, 1.9069, 1.622, 1.8368, 0.4806, 0.5587, 2.1498, 2.1498, 2.1479, 2.1462, 2.1456, 2.1441, 2.1413, 2.1411, 2.1405, 2.1386, 2.138, 2.1378, 2.1361, 2.1322, 2.1321, 2.1301, 2.1298, 2.1296, 2.128, 2.1279, 2.1257, 2.1256, 2.1243, 2.1241, 2.1228, 2.1224, 2.1205, 2.1193, 2.1187, 2.1187, 1.7021, 1.8648, 1.9102, 1.589, 1.9, 1.65, 1.8095, 1.2253, 1.7495, 1.6728, 0.7572, 1.4344, 0.129, 0.541, 0.7075, 0.8519, 0.1643, -0.1255, -0.2281, 2.1812, 2.1806, 2.1792, 2.1791, 2.1785, 2.1779, 2.1756, 2.1752, 2.1743, 2.1714, 2.169, 2.1675, 2.166, 2.1658, 2.1648, 2.1644, 2.1643, 2.1636, 2.1625, 2.1611, 2.1609, 2.16, 2.1576, 2.1568, 2.1548, 2.1546, 2.1542, 2.1511, 2.1503, 2.1459, 2.0281, 1.9661, 1.9346, 1.3011, 0.3837, 2.0264, 0.8134, 1.8412, 0.8551, 0.742, 0.5795, 0.0474, 0.9579, 2.2561, 2.2559, 2.254, 2.2529, 2.2524, 2.2514, 2.2512, 2.2508, 2.2506, 2.2504, 2.2501, 2.2488, 2.2488, 2.2484, 2.2476, 2.2475, 2.2473, 2.2461, 2.246, 2.246, 2.2457, 2.2435, 2.2432, 2.2426, 2.242, 2.2418, 2.2416, 2.2416, 2.2416, 2.2411, 2.202, 2.1055, 2.0944, 1.9747, 2.1636, 2.1613, 2.0247, 1.7283, 1.5273, 1.6144, 0.1236, 0.7482, 1.185, 2.2726, 2.2717, 2.2709, 2.2706, 2.2701, 2.2685, 2.2679, 2.2669, 2.2667, 2.266, 2.2649, 2.2638, 2.2617, 2.2617, 2.2604, 2.2602, 2.2597, 2.2588, 2.2583, 2.2569, 2.2565, 2.2559, 2.2558, 2.255, 2.2549, 2.2548, 2.254, 2.2528, 2.2525, 2.2524, 2.1303, 2.0588, 2.1834, 1.8556, 2.0563, 1.7645, 1.6355, 1.824, 0.7808, 0.2451, 0.8815, 1.2185, 0.941, 1.3235, 2.3475, 2.347, 2.3465, 2.3464, 2.3462, 2.3448, 2.3445, 2.3425, 2.3425, 2.3422, 2.3421, 2.3421, 2.3414, 2.3408, 2.3407, 2.3407, 2.3406, 2.3401, 2.3399, 2.3393, 2.3373, 2.3366, 2.3358, 2.3353, 2.3343, 2.334, 2.3334, 2.3329, 2.3327, 2.3314, 2.3153, 2.3128, 2.0935, 2.2383, 1.9124, 0.9836, 1.4131, 1.7926, 0.6869, 0.8612, 0.251, 0.2143, 2.3894, 2.3891, 2.3889, 2.3889, 2.3887, 2.3861, 2.3861, 2.3859, 2.384, 2.383, 2.383, 2.382, 2.382, 2.3819, 2.3818, 2.3818, 2.3814, 2.381, 2.3809, 2.3808, 2.3794, 2.3788, 2.3779, 2.3778, 2.3775, 2.377, 2.3769, 2.3768, 2.3766, 2.376, 2.3668, 2.2639, 2.29, 2.2097, 2.256, 2.186, 2.2667, 2.1787, 1.9676, 1.5118, -0.0603, 1.9915, 0.2544, 0.3626, 2.4066, 2.4061, 2.4056, 2.4054, 2.4049, 2.4047, 2.4045, 2.4042, 2.404, 2.4036, 2.4024, 2.4023, 2.4022, 2.4018, 2.401, 2.4006, 2.4006, 2.4001, 2.3997, 2.3994, 2.3994, 2.3992, 2.3991, 2.3989, 2.3989, 2.3979, 2.3978, 2.3978, 2.3975, 2.3971, 2.3967, 2.387, 2.1356, 2.0741, 1.9872, 0.4636, 2.4083, 2.4078, 2.4077, 2.4074, 2.4065, 2.4057, 2.4052, 2.4045, 2.4032, 2.4031, 2.403, 2.403, 2.4029, 2.4017, 2.4011, 2.4008, 2.4008, 2.3998, 2.3997, 2.3988, 2.3987, 2.3979, 2.3968, 2.3966, 2.3966, 2.3961, 2.3951, 2.3947, 2.3947, 2.3945, 2.3775, 2.1972, 2.3914, 2.1842, 2.171, 2.0551, 1.9899, 2.1074, 2.0395, 2.0945, 2.1119, 2.0264, 0.6877, 2.5583, 2.5568, 2.5562, 2.556, 2.5548, 2.5544, 2.5543, 2.5537, 2.5536, 2.5534, 2.5533, 2.553, 2.5526, 2.5523, 2.5517, 2.5516, 2.5513, 2.5512, 2.5503, 2.5501, 2.5499, 2.5494, 2.5487, 2.5484, 2.547, 2.5468, 2.5465, 2.5464, 2.5458, 2.5458, 2.5453, 2.3747, 2.0223, 2.4776, 2.0584, 1.9442, 2.0647, 2.2022, 2.2066, 0.6099, 1.8794]}, \"token.table\": {\"Topic\": [4, 6, 7, 3, 2, 8, 1, 5, 10, 1, 3, 4, 5, 8, 9, 1, 5, 2, 8, 1, 5, 9, 8, 1, 7, 3, 4, 9, 7, 3, 7, 4, 1, 7, 9, 7, 10, 7, 4, 1, 4, 6, 2, 10, 8, 6, 8, 9, 8, 5, 2, 4, 7, 3, 6, 1, 1, 2, 8, 10, 10, 1, 2, 9, 1, 10, 10, 7, 4, 10, 5, 2, 4, 2, 10, 3, 2, 7, 5, 9, 10, 2, 6, 9, 8, 6, 1, 1, 2, 5, 6, 9, 10, 4, 4, 10, 4, 5, 9, 10, 5, 9, 1, 6, 3, 10, 9, 9, 1, 4, 7, 1, 10, 2, 3, 1, 3, 6, 7, 5, 5, 8, 7, 5, 8, 2, 1, 10, 10, 9, 6, 10, 1, 3, 4, 5, 10, 5, 6, 8, 1, 2, 6, 4, 7, 2, 8, 10, 4, 1, 8, 7, 4, 9, 2, 8, 1, 7, 6, 10, 1, 5, 5, 2, 4, 10, 10, 9, 5, 8, 9, 1, 9, 7, 3, 3, 4, 2, 5, 9, 8, 3, 7, 6, 6, 9, 4, 1, 2, 6, 9, 2, 2, 2, 4, 3, 1, 1, 4, 6, 6, 1, 2, 3, 4, 6, 7, 8, 9, 10, 9, 8, 7, 10, 6, 3, 6, 9, 6, 2, 10, 7, 1, 9, 8, 4, 10, 9, 8, 2, 7, 2, 7, 2, 4, 9, 10, 4, 6, 9, 4, 3, 10, 9, 4, 9, 3, 7, 2, 4, 6, 7, 8, 9, 10, 4, 2, 9, 4, 6, 7, 3, 7, 5, 6, 7, 5, 7, 9, 4, 9, 4, 7, 6, 6, 6, 4, 6, 9, 9, 4, 8, 9, 1, 2, 8, 8, 1, 8, 1, 5, 8, 8, 6, 10, 8, 1, 5, 7, 2, 8, 8, 5, 3, 6, 9, 8, 1, 3, 10, 1, 2, 8, 2, 4, 6, 10, 9, 8, 6, 1, 2, 5, 10, 1, 2, 7, 10, 9, 2, 9, 10, 2, 6, 5, 2, 2, 4, 6, 8, 9, 9, 4, 7, 2, 4, 6, 1, 7, 7, 9, 4, 8, 10, 3, 6, 10, 2, 3, 3, 2, 1, 9, 5, 5, 4, 1, 9, 10, 8, 9, 5, 9, 3, 8, 2, 4, 1, 6, 10, 8, 5, 3, 4, 4, 1, 5, 1, 8, 9, 9, 1, 6, 10, 10, 7, 1, 2, 1, 6, 7, 10, 6, 1, 2, 3, 4, 5, 7, 5, 7, 1, 2, 5, 6, 7, 10, 2, 4, 7, 3, 7, 4, 1, 1, 2, 10, 2, 5, 10, 9, 8, 9, 1, 9, 10, 6, 10, 6, 7, 1, 2, 3, 5, 7, 10, 7, 8, 5, 5, 2, 9, 3, 8, 2, 5, 7, 10, 8, 2, 2, 5, 7, 8, 10, 3, 6, 2, 8, 8, 4, 7, 5, 7, 10, 9, 3, 3, 9, 5, 6, 3, 2, 4, 4, 7, 10, 3, 5, 1, 2, 6, 10, 5, 6, 7, 5, 1, 5, 6, 9, 10, 2, 7, 10, 2, 3, 3, 3, 4, 5, 6, 2, 6, 3, 5, 1, 1, 5, 7, 2, 3, 5, 7, 4, 4, 4, 7, 1, 1, 2, 3, 6, 7, 9, 3, 2, 5, 9, 10, 4, 8, 4, 1, 10, 2, 4, 7, 5, 3, 5, 9, 3, 9, 1, 2, 3, 9, 3, 4, 6, 2], \"Freq\": [0.9943647579547905, 0.9963647136616303, 0.9801108357346431, 0.9873163591249517, 0.9925898463688979, 0.9948353370609401, 0.8886059326178826, 0.10531625868063793, 0.9968531748604201, 0.003824469304723426, 0.1185585484464262, 0.0879627940086388, 0.34802670672983177, 0.23329262758812896, 0.21034581175978842, 0.9914745822100433, 0.9893539750658037, 0.9954250860204741, 0.9860936320288972, 0.9894607752739817, 0.8068551449167384, 0.1874511952836867, 0.9922195062547409, 0.7968013718789065, 0.20257661996921353, 0.2643240884735504, 0.5254247124535208, 0.20630172758911247, 0.9961349458717644, 0.011198869121111205, 0.9743016135366748, 0.9890591834107474, 0.8172504141901055, 0.16628038730274874, 0.01415152232363819, 0.9923587874323083, 0.9966433894929108, 0.9855639784400008, 0.9888837450605711, 0.9923469102615041, 0.9915130286914502, 0.9866849123596315, 0.48685548127943834, 0.5051125618274173, 0.995687943065153, 0.9926480013084166, 0.9981584785362282, 0.9863068446896076, 0.9938556153790066, 0.9749790985756985, 0.967140973037562, 0.7555617079030177, 0.24331648220605656, 0.9818105384397009, 0.9894741071631842, 0.985507117998859, 0.6019833309314134, 0.2324112859925077, 0.1638309065193087, 0.9825291332429116, 0.9905844545912472, 0.17422077757202825, 0.6194516535894338, 0.19357864174669806, 0.9991352643306448, 0.988207419635737, 0.9965201943703098, 0.9826572465912161, 0.9110784570149453, 0.08176345127057201, 0.9839158716212757, 0.9842393909221204, 0.9960891193240293, 0.9924465362856019, 0.9875990753577449, 0.971940334469137, 0.981547523285371, 0.9862049110160761, 0.9910239044762744, 0.7332308895862688, 0.2630067321342051, 0.967859862776956, 0.9852056091362534, 0.9838777343233214, 0.990509411052737, 0.993998042637296, 0.9757666733791516, 0.23397689910145583, 0.005706753636620874, 0.3880592472902194, 0.09701481182255485, 0.12554858000565922, 0.14837559455214272, 0.991899623428564, 0.9946186101477054, 0.9955619017683578, 0.14279443107558806, 0.26337639509497357, 0.0507713532713202, 0.5394456285077771, 0.9848998900372605, 0.9921675282087494, 0.8731511894239178, 0.12235239597023051, 0.97439839853859, 0.9984542074439007, 0.9898652774151999, 0.9963704437072898, 0.9947608757642918, 0.34151955051790994, 0.6554415616000292, 0.7964612109150121, 0.19200404191701184, 0.9867017532738495, 0.990232435938395, 0.760895470030758, 0.23565046273340637, 0.979431059035794, 0.9943557524738497, 0.9909814439155595, 0.9878867509842261, 0.99719936658949, 0.9854877150857414, 0.9908403653608755, 0.9977918415554958, 0.9702946904160373, 0.9863614508673001, 0.9926211911789157, 0.990201594531529, 0.9973881199780821, 0.9926945641259667, 0.9955454633802115, 0.9903930979079676, 0.9992909826026003, 0.9954231297550636, 0.914046582902665, 0.0823465390002401, 0.22504029361574074, 0.7745768907597967, 0.9941844752455254, 0.9943768094105064, 0.9842358996433535, 0.9970148139969709, 0.9827728108807894, 0.9929590206720442, 0.23565514851454242, 0.7615382167785739, 0.9854981336868864, 0.9871037925173332, 0.9980088423323453, 0.9931385064017204, 0.9980240152378922, 0.02478297471896424, 0.9665360140396054, 0.2809367028095299, 0.716872965789835, 0.9984840098115594, 0.9969563710744093, 0.9941979032448475, 0.005882827829851168, 0.1917649490120426, 0.8073067606556361, 0.9976362491914025, 0.9801810941985407, 0.07077471566223106, 0.9200713036090038, 0.9912560022607425, 0.9948983151613627, 0.9852835166136613, 0.1954631044863749, 0.7990991624590033, 0.9870068923858959, 0.9835102117679118, 0.995632243865089, 0.9813139950263104, 0.1460664122126842, 0.8520540712406579, 0.39706468213797286, 0.600560331733684, 0.9950365314873397, 0.9879127749327317, 0.9712547787064768, 0.9861025623821352, 0.979633968152393, 0.30774880603142873, 0.6802868343852635, 0.9964296010362766, 0.6728270835065148, 0.2002137272782544, 0.1184938385932526, 0.006809990723750149, 0.9911663869114958, 0.9853737807972928, 0.04772577739722971, 0.9449703924651484, 0.9932386740743626, 0.986051895390263, 0.18227571929277847, 0.5906656220120416, 0.2261141834264847, 0.9946044958364246, 0.1536869875284513, 0.03492886080192075, 0.25498068385402145, 0.22179826609219674, 0.06636483552364943, 0.13796900016758695, 0.07684349376422565, 0.05413973424297716, 0.9940438414946516, 0.9891739847241143, 0.996457468672598, 0.8340457045614763, 0.1647497688022669, 0.9971071576186774, 0.9866058854258184, 0.9985865437182984, 0.9907755262528625, 0.9819537510889873, 0.9914894774285554, 0.995471302499418, 0.9953271185202527, 0.9712809725656553, 0.9940997103369459, 0.9973670478490702, 0.9990751237797815, 0.9919420350284538, 0.983594591412842, 0.9953184147998478, 0.1193090254912392, 0.8709558860860462, 0.11791745934405344, 0.8796005075394256, 0.7169976885489486, 0.2775474923415285, 0.29063010719903054, 0.7004930788899711, 0.9951368982755548, 0.9961392290189541, 0.9881435065879641, 0.9970366697763412, 0.9804010251217207, 0.987269195197658, 0.9986290014810068, 0.9986530381499793, 0.9784898427833343, 0.9928424982736495, 0.9928118227214672, 0.009927335189687466, 0.0933169507830622, 0.14891002784531202, 0.4149626109289361, 0.13501175857974956, 0.11714255523831212, 0.07941868151749973, 0.9878635478729619, 0.7871103055787064, 0.2031252401493436, 0.03154803832630647, 0.966722031570391, 0.9951439418281403, 0.9792940692459494, 0.9905594725935191, 0.9786609036719658, 0.18326496918761248, 0.806365864425495, 0.017733805346995323, 0.8157550459617849, 0.16403769945970675, 0.9922416480139813, 0.9913650719277516, 0.09045825831074622, 0.9045825831074622, 0.9959818584383376, 0.9940298555614562, 0.9819822523835342, 0.9912508722299828, 0.18899384371899197, 0.8085649661716875, 0.9950036377136483, 0.16551410335135913, 0.17497205211429392, 0.6573274390239692, 0.7532813119484489, 0.10234800434082186, 0.14328720607715062, 0.9944971130089643, 0.017132682846248654, 0.9765629222361734, 0.9972118967406444, 0.9941690100139844, 0.9909716450913408, 0.9988160421726139, 0.9884144940891691, 0.9923980807885714, 0.9928090334665202, 0.991243237847638, 0.9810973884994143, 0.9875074904874112, 0.962203910775701, 0.9983212225003634, 0.9942479152023601, 0.9981938643737158, 0.9884647033284301, 0.9957071759539587, 0.9963489137392394, 0.9971773382237266, 0.9971104852318872, 0.41479485249043957, 0.5833569041001003, 0.1643962205546966, 0.6382441503888221, 0.19340731829964306, 0.6754352332459903, 0.326460362735562, 0.39337040942284385, 0.6055833934535886, 0.99871777449029, 0.9876469115723053, 0.9976382325513516, 0.2295907135126928, 0.5697251039018674, 0.02267562602594497, 0.17857055495431662, 0.6719445705993714, 0.09292850444459393, 0.1315295755215791, 0.10293618953862711, 0.9990453981792895, 0.9951617007826502, 0.7874120151467483, 0.20388346820764017, 0.9984374616963704, 0.9802335739593658, 0.9904572587359182, 0.963498968363821, 0.08875537096880103, 0.48181487097349124, 0.11834049462506803, 0.12890661021659197, 0.17962396505590683, 0.9870386115730195, 0.9875028899491225, 0.9896025176287881, 0.7791475505570487, 0.20503882909396018, 0.998999812337546, 0.9886175749710837, 0.9984074111444491, 0.30635922590846887, 0.6926382498800165, 0.9859881655547942, 0.9891870299680192, 0.9786588099982457, 0.9981697045578558, 0.16778522032845883, 0.8306743694949928, 0.9975969981810586, 0.9965492028082406, 0.9949227441543195, 0.9629612627461097, 0.9963934867855556, 0.9920787919559753, 0.999412138374447, 0.9940901151371954, 0.9904822044705712, 0.9833308933276719, 0.9977551672821645, 0.9934807885664366, 0.2518233229184633, 0.740207949184574, 0.978943823306918, 0.9818642660223337, 0.9890138960310296, 0.997840580868581, 0.13835104937269624, 0.8602919797356748, 0.08421176711422142, 0.6484306067795049, 0.26526706640979747, 0.9961482320134135, 0.9717021917202742, 0.7126334355329775, 0.2692170756457915, 0.995665619616074, 0.813442746735339, 0.18368062023056042, 0.9799478747528589, 0.6560125594177622, 0.34226742230491936, 0.9810996972711119, 0.02184899276284923, 0.9613556815653661, 0.9955717672992836, 0.9905956841387125, 0.9960661837071844, 0.8243158426102678, 0.16927914625032286, 0.6255905171509791, 0.25518924709945273, 0.11844226658624389, 0.9944289177133024, 0.9933869247140749, 0.4959581141089013, 0.0020472987166518116, 0.16557528370921523, 0.11848741322622358, 0.1316668987146696, 0.08624245843895756, 0.9959896817264564, 0.9961201581884476, 0.20757652075450655, 0.24827779933382155, 0.24827779933382155, 0.051554952867132346, 0.10175319644828752, 0.14245447502760253, 0.6037387088167446, 0.22243005061669538, 0.16523375188668799, 0.9928922862495455, 0.9826593501019463, 0.9818337630117869, 0.9936681504127708, 0.9701763787879124, 0.9834156641063992, 0.9836850202133282, 0.9516006220673556, 0.989138758275617, 0.9947278173939321, 0.9924117673362146, 0.24890570816240914, 0.7467171244872275, 0.7484327184097386, 0.1057567971665935, 0.1464324883845141, 0.9993340845351615, 0.9905180046709411, 0.998541419988534, 0.9777253278164015, 0.9941460025726131, 0.9875093691027721, 0.9974544681955402, 0.000299670863210317, 0.0019478606108670605, 0.0001498354316051585, 0.9896393232816222, 0.9910122038956667, 0.9753562405816023, 0.9974498394685272, 0.9894641104074127, 0.9993483123618373, 0.983997757495868, 0.9946418464107136, 0.2718072272321836, 0.5274354528434039, 0.14237521426447713, 0.05500860551127525, 0.9902097603534262, 0.9997579389037978, 0.9957763771955163, 0.991395396604125, 0.9883140140219704, 0.297479800124826, 0.7012023860085185, 0.9655727897936787, 0.9853829820176315, 0.748535482624184, 0.23953135443973889, 0.9950134737636639, 0.9796416293414278, 0.9991187971961165, 0.9881769774676059, 0.9865779247487865, 0.9897518072372895, 0.9973501568693163, 0.9818793554541533, 0.8635188130047728, 0.12335983042925326, 0.6399686548583393, 0.35745996938033364, 0.9994895507337774, 0.9998232066416322, 0.9997134896873036, 0.3245252947135275, 0.6677732025836046, 0.9859091161827878, 0.974930469778129, 0.9990975688953135, 0.9837987601548882, 0.06704038060636647, 0.3197310459688247, 0.6085203778116341, 0.9950247875048371, 0.9864731461951327, 0.9979647182193931, 0.9915869327878107, 0.970866079132242, 0.07016250880669497, 0.5753325722148988, 0.15435751937472894, 0.19645502465874592, 0.962578411856126, 0.9946683992951877, 0.9896089314098915, 0.9946684154926376, 0.9964655944075442, 0.9968847949077215, 0.2020818415454252, 0.1355738936950321, 0.6599634825154392, 0.0025579979942458885, 0.09894066911533182, 0.8904660220379864, 0.9948528575553279, 0.9938596222042807, 0.9956273670399415, 0.08350398896453541, 0.025051196689360625, 0.8851422830240754, 0.01653024589812789, 0.8595727867026502, 0.01653024589812789, 0.10744659833783128, 0.9927228127633678, 0.9826208120190968, 0.9085751982527963, 0.08451862309328338, 0.9883413108540128, 0.6036823118261525, 0.13713626287385666, 0.11875717609694803, 0.12299850381469617, 0.005655103623664191, 0.011310207247328383, 0.9886987477382541, 0.13280014776910082, 0.8668898534927415, 0.9867266698628632, 0.9796719158420434, 0.9912789411741494, 0.9953443084297061, 0.982135638917202, 0.8745018497323171, 0.1237502617545732, 0.13579204367272577, 0.7943834554854458, 0.06789602183636288, 0.9787362812607224, 0.8067042608069398, 0.005845683049325651, 0.18706185757842084, 0.2947055691275753, 0.7031571473921094, 0.9927484918054116, 0.21178352587421537, 0.7835990457345968, 0.9951029222544826, 0.9620879003502258, 0.9954062356541368, 0.9916535534175259, 0.975266601203443], \"Term\": [\"able\", \"actor\", \"agree\", \"alert\", \"alexei\", \"alive\", \"amazing\", \"amazing\", \"american\", \"amp\", \"amp\", \"amp\", \"amp\", \"amp\", \"amp\", \"annoying\", \"answer\", \"anthology\", \"appreciate\", \"arc\", \"ask\", \"ask\", \"awesome\", \"bad\", \"bad\", \"barb\", \"barb\", \"barb\", \"barbara\", \"believe\", \"believe\", \"benny\", \"big\", \"big\", \"big\", \"billy\", \"binge\", \"bit\", \"blood\", \"bluray\", \"bob\", \"body\", \"book\", \"book\", \"bother\", \"boy\", \"brenner\", \"bring\", \"brother\", \"bug\", \"build\", \"byer\", \"byer\", \"camera\", \"car\", \"case\", \"cast\", \"cast\", \"cast\", \"catch\", \"chance\", \"chapter\", \"chapter\", \"chapter\", \"character\", \"check\", \"chief\", \"christmas\", \"clarke\", \"clarke\", \"class\", \"coincidence\", \"come\", \"comic\", \"comment\", \"community\", \"con\", \"confused\", \"connection\", \"cool\", \"cool\", \"cop\", \"costume\", \"cover\", \"creature\", \"credit\", \"curious\", \"dampd\", \"dampd\", \"dampd\", \"dampd\", \"dampd\", \"dampd\", \"date\", \"daughter\", \"david\", \"day\", \"day\", \"day\", \"day\", \"dead\", \"deal\", \"death\", \"death\", \"demogorgan\", \"demogorgon\", \"deserve\", \"detail\", \"development\", \"die\", \"die\", \"different\", \"different\", \"disappoint\", \"discuss\", \"discussion\", \"discussion\", \"dislike\", \"dog\", \"dragon\", \"drop\", \"duffer\", \"dumb\", \"dungeon\", \"dustin\", \"dyer\", \"early\", \"easter\", \"eat\", \"eddie\", \"effect\", \"egg\", \"eggo\", \"end\", \"enjoy\", \"entire\", \"entire\", \"episode\", \"episode\", \"erica\", \"expect\", \"experience\", \"explain\", \"explanation\", \"fact\", \"fan\", \"fan\", \"fate\", \"father\", \"favorite\", \"favourite\", \"feel\", \"fight\", \"fight\", \"film\", \"film\", \"final\", \"finale\", \"find\", \"find\", \"finish\", \"finish\", \"flayer\", \"font\", \"food\", \"food\", \"foreshadow\", \"forget\", \"free\", \"friend\", \"friend\", \"fuck\", \"fucking\", \"fun\", \"funny\", \"future\", \"future\", \"game\", \"game\", \"gate\", \"gay\", \"general\", \"genre\", \"gif\", \"girl\", \"girl\", \"gon\", \"good\", \"good\", \"good\", \"good\", \"goonie\", \"government\", \"great\", \"great\", \"grow\", \"guess\", \"guy\", \"guy\", \"guy\", \"halloween\", \"happen\", \"happen\", \"happen\", \"happen\", \"happen\", \"happen\", \"happen\", \"happen\", \"harbour\", \"harrington\", \"hate\", \"hawkin\", \"hawkin\", \"hear\", \"heart\", \"help\", \"hero\", \"hey\", \"hide\", \"high\", \"hole\", \"holy\", \"hop\", \"hope\", \"hopper\", \"horror\", \"hot\", \"hour\", \"house\", \"house\", \"idea\", \"idea\", \"influence\", \"influence\", \"interesting\", \"interesting\", \"intro\", \"issue\", \"jacket\", \"jim\", \"join\", \"joke\", \"jonathan\", \"joyce\", \"july\", \"jump\", \"kali\", \"kid\", \"kid\", \"kid\", \"kid\", \"kid\", \"kid\", \"kid\", \"kind\", \"king\", \"king\", \"know\", \"know\", \"lab\", \"lack\", \"late\", \"learn\", \"leave\", \"leave\", \"let\", \"let\", \"let\", \"letter\", \"life\", \"light\", \"light\", \"like\", \"list\", \"listen\", \"live\", \"look\", \"look\", \"lose\", \"lot\", \"lot\", \"lot\", \"love\", \"love\", \"love\", \"luca\", \"lucas\", \"lucas\", \"main\", \"mall\", \"man\", \"max\", \"maxs\", \"mean\", \"meet\", \"member\", \"meme\", \"mention\", \"merch\", \"mike\", \"millie\", \"mind\", \"minor\", \"minute\", \"miss\", \"mom\", \"moment\", \"monster\", \"monster\", \"movie\", \"movie\", \"movie\", \"murray\", \"murray\", \"music\", \"music\", \"nancy\", \"nancys\", \"need\", \"netflix\", \"netflix\", \"netflix\", \"netflix\", \"new\", \"new\", \"new\", \"new\", \"notice\", \"official\", \"open\", \"open\", \"opinion\", \"order\", \"parallel\", \"pay\", \"people\", \"people\", \"people\", \"people\", \"people\", \"person\", \"petition\", \"pick\", \"plan\", \"plan\", \"play\", \"player\", \"plot\", \"point\", \"point\", \"poor\", \"pop\", \"portal\", \"possible\", \"post\", \"post\", \"poster\", \"potential\", \"power\", \"predict\", \"prediction\", \"problem\", \"question\", \"quick\", \"random\", \"rank\", \"real\", \"realize\", \"reason\", \"reason\", \"recommend\", \"recommendation\", \"reddit\", \"reference\", \"release\", \"release\", \"remind\", \"remind\", \"remind\", \"request\", \"retro\", \"return\", \"return\", \"rewatch\", \"rewatche\", \"rewatche\", \"ride\", \"robin\", \"robin\", \"room\", \"run\", \"run\", \"russian\", \"ryder\", \"sad\", \"scary\", \"scary\", \"scene\", \"scene\", \"scene\", \"school\", \"score\", \"season\", \"season\", \"season\", \"season\", \"season\", \"season\", \"second\", \"sense\", \"series\", \"series\", \"series\", \"series\", \"series\", \"series\", \"set\", \"set\", \"set\", \"shadow\", \"share\", \"shirt\", \"shit\", \"short\", \"shower\", \"significance\", \"silence\", \"silent\", \"similar\", \"similarity\", \"sister\", \"sister\", \"small\", \"small\", \"small\", \"song\", \"sound\", \"soundtrack\", \"speak\", \"speculation\", \"spinoff\", \"spoiler\", \"spoiler\", \"spoiler\", \"spoiler\", \"stand\", \"star\", \"starcourt\", \"start\", \"stephen\", \"steve\", \"stick\", \"stop\", \"story\", \"story\", \"story\", \"story\", \"storyline\", \"strange\", \"stranger\", \"stupid\", \"style\", \"sub\", \"sub\", \"subject\", \"suggestion\", \"super\", \"super\", \"suzie\", \"synth\", \"talk\", \"target\", \"team\", \"teaser\", \"tell\", \"terry\", \"test\", \"test\", \"theme\", \"theme\", \"theory\", \"thing\", \"think\", \"thought\", \"thought\", \"thread\", \"til\", \"time\", \"timeline\", \"title\", \"title\", \"title\", \"today\", \"track\", \"trailer\", \"travel\", \"trope\", \"try\", \"try\", \"try\", \"try\", \"twin\", \"type\", \"understand\", \"unpopular\", \"upside\", \"upsidedown\", \"vecna\", \"vecna\", \"vecna\", \"vecna\", \"version\", \"version\", \"vibe\", \"video\", \"villain\", \"vol\", \"vol\", \"vol\", \"volume\", \"volume\", \"volume\", \"volume\", \"wait\", \"walk\", \"wall\", \"wall\", \"wanna\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"warning\", \"watch\", \"watch\", \"wear\", \"week\", \"weird\", \"wheeler\", \"win\", \"wish\", \"wish\", \"wonder\", \"wonder\", \"wonder\", \"wood\", \"work\", \"work\", \"work\", \"world\", \"world\", \"wow\", \"write\", \"write\", \"wrong\", \"xman\", \"year\", \"young\", \"youtube\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 7, 10, 9, 3, 1, 4, 6, 2, 8]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el564951465521284197215926\", ldavis_el564951465521284197215926_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el564951465521284197215926\", ldavis_el564951465521284197215926_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el564951465521284197215926\", ldavis_el564951465521284197215926_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "4     -0.179677  0.046999       1        1  11.869184\n",
       "6      0.102148  0.147810       2        1  11.648619\n",
       "9     -0.219665 -0.127565       3        1  11.285930\n",
       "8     -0.130265 -0.127777       4        1  10.471996\n",
       "2     -0.116455  0.161734       5        1  10.300078\n",
       "0      0.118651  0.188696       6        1   9.549113\n",
       "3     -0.117841 -0.024911       7        1   9.153812\n",
       "5      0.197092 -0.195795       8        1   9.001450\n",
       "1      0.197072 -0.185230       9        1   8.988823\n",
       "7      0.148940  0.116040      10        1   7.730994, topic_info=             Term         Freq        Total Category  logprob  loglift\n",
       "12        spoiler  6673.000000  6673.000000  Default  30.0000  30.0000\n",
       "16          thing  5135.000000  5135.000000  Default  29.0000  29.0000\n",
       "15        strange  4279.000000  4279.000000  Default  28.0000  28.0000\n",
       "6          season  7815.000000  7815.000000  Default  27.0000  27.0000\n",
       "20          think  2583.000000  2583.000000  Default  26.0000  26.0000\n",
       "...           ...          ...          ...      ...      ...      ...\n",
       "232         title   118.170302   193.912980  Topic10  -4.6432   2.0647\n",
       "1107          sub    98.722121   141.186057  Topic10  -4.8230   2.2022\n",
       "146   interesting    94.246313   134.191190  Topic10  -4.8694   2.2066\n",
       "81         series   104.860255   737.077582  Topic10  -4.7627   0.6099\n",
       "699          book    83.199346   164.319810  Topic10  -4.9941   1.8794\n",
       "\n",
       "[464 rows x 6 columns], token_table=      Topic      Freq     Term\n",
       "term                          \n",
       "214       4  0.994365     able\n",
       "73        6  0.996365    actor\n",
       "576       7  0.980111    agree\n",
       "597       3  0.987316    alert\n",
       "1388      2  0.992590   alexei\n",
       "...     ...       ...      ...\n",
       "1032      9  0.995103    wrong\n",
       "1195      3  0.962088     xman\n",
       "460       4  0.995406     year\n",
       "785       6  0.991654    young\n",
       "2576      2  0.975267  youtube\n",
       "\n",
       "[562 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[5, 7, 10, 9, 3, 1, 4, 6, 2, 8])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pyLDAvis.gensim_models\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#https://pyldavis.readthedocs.io/en/latest/readme.html\n",
    "\n",
    "\n",
    "### COMMENT IN TO SEE DETAILED RESULTS ###\n",
    "#pyLDAvis.enable_notebook()\n",
    "#pyLDAvis.enable_notebook()\n",
    "#vis = pyLDAvis.gensim_models.prepare(lda_model_final, bow_corpus, dictionary)\n",
    "#vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008c1242",
   "metadata": {},
   "source": [
    "### look at perplexity score and log likelihood and distance measures/similarity measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc97deb3",
   "metadata": {},
   "source": [
    "### Try tuned model with our dicitonary based on our corpus of docs versus the standard genism dictionary.  This is because our dictionary has around 56,308 keys; this is very long. So we are going to try both ways and check scores again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4146ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca6ff62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
